{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2-DM0iIJQ2f"
   },
   "source": [
    "# Review-based Music Recommendation System - Fine Tune BERT\n",
    "by Yuzhou Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JSXjPUeJ-eN"
   },
   "source": [
    "## Install the neccessary associates and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7XjKr92Jj0E",
    "outputId": "4f33823d-45ad-4d5a-b978-908b36b87cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (4.10.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (0.0.16)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# install the huggingface transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eju5DMX0VTC",
    "outputId": "ad42a712-8b8f-48ea-903e-1d0ab3b513cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (8.0.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: pathtools in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (3.1.18)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPtLoViGwQqY",
    "outputId": "d0ad4405-9c1f-4f58-b784-a900dbd8b989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (4.62.2)\n",
      "Requirement already satisfied: regex in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (2021.8.28)\n",
      "Requirement already satisfied: joblib in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oe22bcbslB87",
    "outputId": "3cc60f67-26f1-4db9-c24f-03cb7046f01a"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/Colab Notebooks/rating_prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kw9dqA_90S2O",
    "outputId": "a5ee1036-cc2a-4220-de49-76de1851d31a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kevinzhenshuai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kevinzhenshuai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import wandb\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrqOsDeQ-KGn",
    "outputId": "08bcb1fa-9dac-41ab-fc03-57817b522479"
   },
   "outputs": [],
   "source": [
    "# change the current working dir and check\n",
    "# %cd /content/drive/MyDrive/Colab Notebooks/rating_prediction/\n",
    "# print('current working dir is {}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJq1FH3oq1Ds"
   },
   "source": [
    "Mount the notebook on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "DEfSbAA4QHas",
    "outputId": "9486447f-c9c8-4586-8bb2-d3b34c343516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "db6b4319-ebcc-4085-ca86-e6fad258f3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLCEAHesbEyh"
   },
   "source": [
    "## Get preprocessed data, if exist, skip to model training/fine tuning section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SXx5Zivrj6kn"
   },
   "outputs": [],
   "source": [
    "def get_dataset(processed_data_dir):\n",
    "    if os.path.exists(processed_data_dir):\n",
    "        train_processed = dict(np.load(os.path.join(processed_data_dir, \"train_bert.npz\")))\n",
    "        valid_processed = dict(np.load(os.path.join(processed_data_dir, \"valid_bert.npz\")))\n",
    "        test_processed = dict(np.load(os.path.join(processed_data_dir, \"test_bert.npz\")))\n",
    "\n",
    "        train_labels = train_processed[\"labels\"].astype(np.float32)\n",
    "        valid_labels = valid_processed[\"labels\"].astype(np.float32)\n",
    "        del train_processed[\"labels\"]\n",
    "        del valid_processed[\"labels\"]\n",
    "\n",
    "        train_encodings = train_processed\n",
    "        valid_encodings = valid_processed\n",
    "        test_encodings = test_processed\n",
    "\n",
    "        print(f\"=> Loaded pre-processed data from {processed_data_dir}!\")\n",
    "\n",
    "        return train_encodings, valid_encodings, test_encodings, train_labels, valid_labels\n",
    "    else: \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pa579Eodk8JO",
    "outputId": "72f82a79-0593-41d0-e83a-262afbedf6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded pre-processed data from ./processed!\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = './processed'\n",
    "train_encodings, valid_encodings, test_encodings, train_labels, valid_labels = get_dataset(processed_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNn6QVL8KiRy"
   },
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42HEZiQWLS2q"
   },
   "source": [
    "Load dataset into Pandas dataframes and select fileds of interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6oZ5g6sMGQEJ"
   },
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "total_train_df = pd.read_json(\"./train.json\", lines=True)\n",
    "test_df = pd.read_json('./test.json', lines=True)\n",
    "\n",
    "# split into train and validation set\n",
    "train_df, valid_df = train_test_split(total_train_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "u8ZLVw_VMLX6",
    "outputId": "467315cb-5b4c-4d02-8fd8-82e50a4f3578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 160000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153248</th>\n",
       "      <td>5</td>\n",
       "      <td>09 27, 2015</td>\n",
       "      <td>u03549356</td>\n",
       "      <td>Better than expected from an old P.C.fan. Awes...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1443312000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$8.95</td>\n",
       "      <td>p10577861</td>\n",
       "      <td>13148837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67802</th>\n",
       "      <td>5</td>\n",
       "      <td>03 28, 2018</td>\n",
       "      <td>u47382696</td>\n",
       "      <td>Good old school music</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1522195200</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$7.98</td>\n",
       "      <td>p91232752</td>\n",
       "      <td>32439111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148889</th>\n",
       "      <td>5</td>\n",
       "      <td>04 24, 2015</td>\n",
       "      <td>u90648201</td>\n",
       "      <td>Wonderful to hear the old spirituals, delivery...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1429833600</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$7.98</td>\n",
       "      <td>p26611367</td>\n",
       "      <td>52727907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103093</th>\n",
       "      <td>5</td>\n",
       "      <td>12 4, 2016</td>\n",
       "      <td>u48360742</td>\n",
       "      <td>awecome</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1480809600</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$9.89</td>\n",
       "      <td>p74392498</td>\n",
       "      <td>47887987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104681</th>\n",
       "      <td>5</td>\n",
       "      <td>08 11, 2015</td>\n",
       "      <td>u35451292</td>\n",
       "      <td>Worth your time to listen and enjoy. Take with...</td>\n",
       "      <td>Put a copy in your car for a better rush hiour!</td>\n",
       "      <td>1439251200</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$14.89</td>\n",
       "      <td>p58571849</td>\n",
       "      <td>76776786</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall   reviewTime reviewerID  \\\n",
       "153248        5  09 27, 2015  u03549356   \n",
       "67802         5  03 28, 2018  u47382696   \n",
       "148889        5  04 24, 2015  u90648201   \n",
       "103093        5   12 4, 2016  u48360742   \n",
       "104681        5  08 11, 2015  u35451292   \n",
       "\n",
       "                                               reviewText  \\\n",
       "153248  Better than expected from an old P.C.fan. Awes...   \n",
       "67802                               Good old school music   \n",
       "148889  Wonderful to hear the old spirituals, delivery...   \n",
       "103093                                            awecome   \n",
       "104681  Worth your time to listen and enjoy. Take with...   \n",
       "\n",
       "                                                summary  unixReviewTime  \\\n",
       "153248                                       Five Stars      1443312000   \n",
       "67802                                        Five Stars      1522195200   \n",
       "148889                                       Five Stars      1429833600   \n",
       "103093                                       Five Stars      1480809600   \n",
       "104681  Put a copy in your car for a better rush hiour!      1439251200   \n",
       "\n",
       "       category   price     itemID  reviewHash image  \n",
       "153248      Pop   $8.95  p10577861    13148837   NaN  \n",
       "67802      Jazz   $7.98  p91232752    32439111   NaN  \n",
       "148889     Jazz   $7.98  p26611367    52727907   NaN  \n",
       "103093      Pop   $9.89  p74392498    47887987   NaN  \n",
       "104681     Jazz  $14.89  p58571849    76776786   NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train set size: {}'.format(len(train_df)))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "FwD9ldE_L7Lw",
    "outputId": "ae04cd2b-312a-4a75-9811-5d513a399033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set size: 40000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119737</th>\n",
       "      <td>4</td>\n",
       "      <td>01 15, 2006</td>\n",
       "      <td>u97014128</td>\n",
       "      <td>I can't help but notice that people think dona...</td>\n",
       "      <td>Decent album</td>\n",
       "      <td>1137283200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$13.98</td>\n",
       "      <td>p09608072</td>\n",
       "      <td>52079253</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72272</th>\n",
       "      <td>5</td>\n",
       "      <td>06 9, 2017</td>\n",
       "      <td>u19429623</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1496966400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$14.95</td>\n",
       "      <td>p31077493</td>\n",
       "      <td>94739968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158154</th>\n",
       "      <td>5</td>\n",
       "      <td>05 10, 2012</td>\n",
       "      <td>u14022356</td>\n",
       "      <td>I can only start by saying WOW ! If this album...</td>\n",
       "      <td>The Magic of Natural Ability</td>\n",
       "      <td>1336608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.56</td>\n",
       "      <td>p29932381</td>\n",
       "      <td>70320054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65426</th>\n",
       "      <td>5</td>\n",
       "      <td>05 9, 2004</td>\n",
       "      <td>u10784805</td>\n",
       "      <td>If you like showoff check out chris from showo...</td>\n",
       "      <td>FME</td>\n",
       "      <td>1084060800</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$12.97</td>\n",
       "      <td>p50896575</td>\n",
       "      <td>69912366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30074</th>\n",
       "      <td>5</td>\n",
       "      <td>05 8, 2006</td>\n",
       "      <td>u52616966</td>\n",
       "      <td>This CD is one of my favorites - and was the f...</td>\n",
       "      <td>Spectacular - buy this!!!</td>\n",
       "      <td>1147046400</td>\n",
       "      <td>Classical</td>\n",
       "      <td>$15.77</td>\n",
       "      <td>p91635054</td>\n",
       "      <td>56966130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall   reviewTime reviewerID  \\\n",
       "119737        4  01 15, 2006  u97014128   \n",
       "72272         5   06 9, 2017  u19429623   \n",
       "158154        5  05 10, 2012  u14022356   \n",
       "65426         5   05 9, 2004  u10784805   \n",
       "30074         5   05 8, 2006  u52616966   \n",
       "\n",
       "                                               reviewText  \\\n",
       "119737  I can't help but notice that people think dona...   \n",
       "72272                                           Excellent   \n",
       "158154  I can only start by saying WOW ! If this album...   \n",
       "65426   If you like showoff check out chris from showo...   \n",
       "30074   This CD is one of my favorites - and was the f...   \n",
       "\n",
       "                             summary  unixReviewTime          category  \\\n",
       "119737                  Decent album      1137283200               Pop   \n",
       "72272                     Five Stars      1496966400               Pop   \n",
       "158154  The Magic of Natural Ability      1336608000               Pop   \n",
       "65426                            FME      1084060800  Alternative Rock   \n",
       "30074      Spectacular - buy this!!!      1147046400         Classical   \n",
       "\n",
       "         price     itemID  reviewHash image  \n",
       "119737  $13.98  p09608072    52079253   NaN  \n",
       "72272   $14.95  p31077493    94739968   NaN  \n",
       "158154  $11.56  p29932381    70320054   NaN  \n",
       "65426   $12.97  p50896575    69912366   NaN  \n",
       "30074   $15.77  p91635054    56966130   NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('validation set size: {}'.format(len(valid_df)))\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFNKgM7LL9Jv",
    "outputId": "932811b7-6573-4c96-a6c6-88af8a83ea37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "C:\\Users\\kevinzhenshuai\\AppData\\Local\\Temp/ipykernel_14744/442363543.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewAll'] = df['summary'] + ' ' + df['reviewText']\n"
     ]
    }
   ],
   "source": [
    "# preprocess fields of data\n",
    "all_dfs = [train_df, valid_df, test_df]\n",
    "fillna_fields = ['reviewText', 'summary']\n",
    "del_fields = [\"reviewTime\", \"unixReviewTime\", \"reviewHash\", \"image\"]\n",
    "\n",
    "for df in all_dfs:\n",
    "  # Fill N/A text with empy string\n",
    "  for field in fillna_fields:\n",
    "    df[field].fillna('', inplace=True)\n",
    "\n",
    "  # Delete unnecessary fields\n",
    "  for field in del_fields:\n",
    "    del df[field]\n",
    "\n",
    "  # concat reviewText and summary as the overall review feature\n",
    "  df['reviewAll'] = df['summary'] + ' ' + df['reviewText']\n",
    "  del df['reviewText']\n",
    "  del df['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "fwjgOJirOT9K",
    "outputId": "4e5c647b-ca62-48e7-95ec-7d7ab1936a6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewAll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153248</th>\n",
       "      <td>5</td>\n",
       "      <td>u03549356</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$8.95</td>\n",
       "      <td>p10577861</td>\n",
       "      <td>Five Stars Better than expected from an old P....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67802</th>\n",
       "      <td>5</td>\n",
       "      <td>u47382696</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$7.98</td>\n",
       "      <td>p91232752</td>\n",
       "      <td>Five Stars Good old school music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148889</th>\n",
       "      <td>5</td>\n",
       "      <td>u90648201</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$7.98</td>\n",
       "      <td>p26611367</td>\n",
       "      <td>Five Stars Wonderful to hear the old spiritual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103093</th>\n",
       "      <td>5</td>\n",
       "      <td>u48360742</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$9.89</td>\n",
       "      <td>p74392498</td>\n",
       "      <td>Five Stars awecome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104681</th>\n",
       "      <td>5</td>\n",
       "      <td>u35451292</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$14.89</td>\n",
       "      <td>p58571849</td>\n",
       "      <td>Put a copy in your car for a better rush hiour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  ...                                          reviewAll\n",
       "153248        5  ...  Five Stars Better than expected from an old P....\n",
       "67802         5  ...                   Five Stars Good old school music\n",
       "148889        5  ...  Five Stars Wonderful to hear the old spiritual...\n",
       "103093        5  ...                                 Five Stars awecome\n",
       "104681        5  ...  Put a copy in your car for a better rush hiour...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display sample processed dfs\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "JCXhOMvRODR5"
   },
   "outputs": [],
   "source": [
    "# define ratings as the target variables\n",
    "train_labels = train_df.overall.to_numpy().astype(np.float32)\n",
    "valid_labels = valid_df.overall.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "LFA4XxFzkp05"
   },
   "outputs": [],
   "source": [
    "def html_escaping(text):\n",
    "    '''html escaping: Html character codes (i.e., &...;) are replaced with an ASCII equivalent'''\n",
    "    return html.unescape(text)\n",
    "\n",
    "def to_lower(text):\n",
    "    '''lower case all words in text'''\n",
    "    return text.lower()\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', ' ', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    '''remove urls'''\n",
    "    return re.sub(r\"http\\S+\", ' ', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    '''Remove punctuation from text'''\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        \n",
    "def denoise_text(text):\n",
    "    text = str(text) # make sure all inputs are type string\n",
    "    text = to_lower(text)\n",
    "    text = strip_html(text)\n",
    "    text = html_escaping(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text\n",
    "\n",
    "def word_extraction(text):    \n",
    "    '''removing stopwords from the sentence and tokenize the sentence'''\n",
    "    stop_words = set(stopwords.words('english'))\n",
    " \n",
    "    word_tokens = word_tokenize(text)\n",
    "  \n",
    "    filtered_sentence = ''\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + ' ' + w   \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "h-bgb4xMwivk",
    "outputId": "fc33a8f5-00c5-4b80-b71a-cf9a8fc2dbd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Amazing that I Actually Bought This...More Amazing that I Actually LOVE This! So is Katy Perry\\'s new album \"Teenage Dream\" contrived, derived and unoriginal?  The answer to all three would be a resounding yes! So why on earth in spite of this fact is her new album so unbelievably great????  Well, the answer may be complicated if not impossible to fully answer.  The simple brilliance of Katy Perry would be simplicity and self awareness....thus the brilliant cover art of her nude in clouds that reveal Katy for what she truly is...an absolutely gorgeous young woman with very a simple, straight forward message....give them what they want.  And Katy delivers!!!....Take a song like \"Pearl\" ...which I believe happens to be the gem of the entire album....it\\'s a lush, gaudy, maudlin, tribute to \"woman power\" and although the lyrics are silly beyond belief,  it may be just the song many girls need these days.  Another winner here is \"who am I living for?\".....I really liked this song, as it has a very European feel to it and it has another very simplistic but resonant message that many will relate to.  Other stand-outs include the track \"Firework\" which sounds reminiscent of just about any track on LeAnn Rimes \"Twisted Angel\" album and the fun as hell yet most irresponsible track  \"Last Friday Night\".  Immediate hits such as \"California Gurls\" are OK and fun but overheard at this point so they will be most likely skipped over..but the beauty is that there are plenty of other addictive tracks in waiting! Finally, Kudos also to pristine production, as the album sounds loud, clear and near when headphones are one.  Well done Katy!!!'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.reviewAll[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess review texts before tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_escaping(text):\n",
    "    '''html escaping: Html character codes (i.e., &...;) are replaced with an ASCII equivalent'''\n",
    "    return html.unescape(text)\n",
    "\n",
    "def to_lower(text):\n",
    "    '''lower case all words in text'''\n",
    "    return text.lower()\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', ' ', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    '''remove urls'''\n",
    "    return re.sub(r\"http\\S+\", ' ', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    '''Remove punctuation from text'''\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        \n",
    "def denoise_text(text):\n",
    "    text = str(text) # make sure all inputs are type string\n",
    "    text = to_lower(text)\n",
    "    text = strip_html(text)\n",
    "    text = html_escaping(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text\n",
    "\n",
    "def word_extraction(text):    \n",
    "    '''removing stopwords from the sentence and tokenize the sentence'''\n",
    "    stop_words = set(stopwords.words('english'))\n",
    " \n",
    "    word_tokens = word_tokenize(text)\n",
    "  \n",
    "    filtered_sentence = ''\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + ' ' + w   \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_dbK7gThv1b",
    "outputId": "47e553c1-7305-4672-e127-8b4962cc3651"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\AppData\\Local\\Temp/ipykernel_14744/3904086986.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewAll'] = df.reviewAll.apply(lambda x: denoise_text(x))\n",
      "C:\\Users\\kevinzhenshuai\\AppData\\Local\\Temp/ipykernel_14744/3904086986.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewAll'] = df.reviewAll.apply(lambda x: word_extraction(x))\n"
     ]
    }
   ],
   "source": [
    "# text preprocessing\n",
    "for df in all_dfs:\n",
    "    df['reviewAll'] = df.reviewAll.apply(lambda x: denoise_text(x))\n",
    "    df['reviewAll'] = df.reviewAll.apply(lambda x: word_extraction(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5DEz_20O9YB"
   },
   "source": [
    "### Tokenization and input formatting for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "douL96pxO6zb"
   },
   "outputs": [],
   "source": [
    "# Tokenization with the BERT special tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-DCwVdgYU2a"
   },
   "source": [
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "*  All sentences must be padded or truncated to a single, fixed length.\n",
    "*  The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "IT0wy_izUiXS",
    "outputId": "812f8804-6c9f-4fb0-fb96-ab633d8588fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.5187e+04, 7.5860e+03, 3.3620e+03, 1.6500e+03, 8.9600e+02,\n",
       "        5.1500e+02, 3.2700e+02, 1.7100e+02, 1.1100e+02, 5.7000e+01,\n",
       "        3.4000e+01, 2.1000e+01, 2.4000e+01, 1.6000e+01, 8.0000e+00,\n",
       "        9.0000e+00, 7.0000e+00, 0.0000e+00, 2.0000e+00, 4.0000e+00,\n",
       "        0.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([2.00000e+00, 7.09600e+01, 1.39920e+02, 2.08880e+02, 2.77840e+02,\n",
       "        3.46800e+02, 4.15760e+02, 4.84720e+02, 5.53680e+02, 6.22640e+02,\n",
       "        6.91600e+02, 7.60560e+02, 8.29520e+02, 8.98480e+02, 9.67440e+02,\n",
       "        1.03640e+03, 1.10536e+03, 1.17432e+03, 1.24328e+03, 1.31224e+03,\n",
       "        1.38120e+03, 1.45016e+03, 1.51912e+03, 1.58808e+03, 1.65704e+03,\n",
       "        1.72600e+03, 1.79496e+03, 1.86392e+03, 1.93288e+03, 2.00184e+03,\n",
       "        2.07080e+03, 2.13976e+03, 2.20872e+03, 2.27768e+03, 2.34664e+03,\n",
       "        2.41560e+03, 2.48456e+03, 2.55352e+03, 2.62248e+03, 2.69144e+03,\n",
       "        2.76040e+03, 2.82936e+03, 2.89832e+03, 2.96728e+03, 3.03624e+03,\n",
       "        3.10520e+03, 3.17416e+03, 3.24312e+03, 3.31208e+03, 3.38104e+03,\n",
       "        3.45000e+03]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# investigate the maximum length of reviewAll after Tokenization\n",
    "plt.hist((valid_df['reviewAll'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))).values, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeqkTOsZ3dF7",
    "outputId": "7bca6e4d-6080-48a1-ba30-7bc9d966f13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean        83.043925\n",
       "std        113.504875\n",
       "min          2.000000\n",
       "25%         16.000000\n",
       "50%         44.000000\n",
       "75%        106.000000\n",
       "max       3450.000000\n",
       "Name: reviewAll, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_df['reviewAll'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=True)))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ0pUgorYeWl"
   },
   "source": [
    "sicne majority of data contain tokenized text of length less than 256 approximately, use MAX_LENGTH = 256 (arbitrarily) for padding and truncation for run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqIGCg5kYG38",
    "outputId": "8b9b6d23-a2ec-4b04-a682-17210aaddf53"
   },
   "outputs": [],
   "source": [
    "# Tokenize reviewText with padding and truncation to max length 256\n",
    "train_encodings = tokenizer(train_df.reviewAll.tolist(), truncation=True, padding='max_length', max_length=256)\n",
    "valid_encodings = tokenizer(valid_df.reviewAll.tolist(), truncation=True, padding='max_length', max_length=256)\n",
    "test_encodings = tokenizer(test_df.reviewAll.tolist(), truncation=True, padding='max_length', max_length=256)\n",
    "print(\"=> Loaded and pre-processed data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8Ujrb_7geWV",
    "outputId": "cbf2d7dc-48c9-4cd5-b8b8-ff3b74672b0b"
   },
   "outputs": [],
   "source": [
    "# save preprocessed data to './processed'\n",
    "train_processed = dict(train_encodings)\n",
    "train_processed.update(labels=train_labels)\n",
    "valid_processed = dict(valid_encodings)\n",
    "valid_processed.update(labels=valid_labels)\n",
    "test_processed = dict(test_encodings)\n",
    "\n",
    "processed_data_dir = './processed'\n",
    "os.makedirs(processed_data_dir)\n",
    "\n",
    "np.savez(os.path.join(processed_data_dir, \"train_bert.npz\"), **train_processed)\n",
    "np.savez(os.path.join(processed_data_dir, \"valid_bert.npz\"), **valid_processed)\n",
    "np.savez(os.path.join(processed_data_dir, \"test_bert.npz\"), **test_processed)\n",
    "\n",
    "print(f\"=> Save pre-processed data to {processed_data_dir}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8iyOXeJhYhJ"
   },
   "source": [
    "## Model Training - Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kWoojq-XKmne"
   },
   "outputs": [],
   "source": [
    "class AmazonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(sefl, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> computing on GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# arguments variables\n",
    "class Args: \n",
    "    def __init__(self):\n",
    "        self.batch_size = 12\n",
    "        self.eval_batch_size = 32\n",
    "        self.lr = 5e-5\n",
    "        self.max_epochs = 3\n",
    "        self.log_steps = 10\n",
    "        self.eval_steps = 5000\n",
    "        \n",
    "        self.processed_data_dir = './processed'\n",
    "        self.ckpt_dir = '/checkpoint/ywu/'\n",
    "        self.exp_name = 'bert_finetune'\n",
    "        self.ckpt_path = ''\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda') \n",
    "            print('=> computing on GPU: {}'.format(torch.cuda.get_device_name(0)))\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            print('=> computing on CPU')\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "v67UOWRmhcCS"
   },
   "outputs": [],
   "source": [
    "# convert inputs to torch tensor dataset\n",
    "train_dataset = AmazonDataset(train_encodings, train_labels)\n",
    "valid_dataset = AmazonDataset(valid_encodings, valid_labels)\n",
    "test_dataset = AmazonDataset(test_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)  # already shuffled\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=args.eval_batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.eval_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "SL94doVJqICj"
   },
   "outputs": [],
   "source": [
    "# define evaluation function to evalulate the performance after each epoch\n",
    "def eval(step, args, model, valid_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    # create progress bar by wrapping around epochs\n",
    "    pbar = tqdm(valid_loader)\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using    \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "            input_ids = batch['input_ids'].to(args.device).long()\n",
    "            attention_mask = batch['attention_mask'].to(args.device)\n",
    "            labels = batch['labels'].to(args.device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            pbar.set_description(\"Eval Loss {:.3f}\".format(loss.item()))\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    eval_loss = np.mean(losses)\n",
    "    print('=> Step: {} Eval loss: {:.6f}'.format(step, eval_loss))\n",
    "    return eval_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQnMzugdskya"
   },
   "source": [
    "define pretrained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "    print(\"=> Loaded pretrained model!\")\n",
    "    return model\n",
    "\n",
    "def get_optimizer(args, model):\n",
    "    optimizer = AdamW(model.parameters(), lr=args.lr)\n",
    "    return optimizer\n",
    "\n",
    "# init visualization with W&B\n",
    "def init_logger(args):\n",
    "    wandb.init(project=\"rate-prediction-BERT\",\n",
    "               name=args.exp_name, config=args, resume=True, id=args.exp_name,\n",
    "               dir=args.ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dECrJ4g_QopS"
   },
   "outputs": [],
   "source": [
    "def finetune(args,train_loader, valid_loader, test_loader):\n",
    "    args.ckpt_dir = os.path.join(args.ckpt_dir, args.exp_name)\n",
    "    if not os.path.exists(args.ckpt_dir):\n",
    "        os.makedirs(args.ckpt_dir)\n",
    "\n",
    "    init_logger(args)\n",
    "    model = get_model(args)\n",
    "    model.to(args.device)\n",
    "    optim = get_optimizer(args, model)\n",
    "\n",
    "\n",
    "    ckpt_path_all = glob.glob(os.path.join(args.ckpt_dir, \"model-*.pt\"))\n",
    "    if len(ckpt_path_all) > 0:\n",
    "        ckpt_steps = [int(name.split(\"model-\")[1].split(\".pt\")[0]) for name in ckpt_path_all if \"model-best.pt\" not in name]\n",
    "        ckpt_path_last = ckpt_path_all[np.argmax(ckpt_steps)]\n",
    "\n",
    "        checkpoint = torch.load(ckpt_path_last, map_location='cpu')\n",
    "        step = checkpoint['step']\n",
    "        min_eval_loss = checkpoint['min_eval_loss']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"=> Loaded checkpoint from '{}' (step {})\".format(ckpt_path_last, step))\n",
    "        if step >= (args.max_epochs * len(train_loader)):\n",
    "            print(f\"=> Finished training (step {step})!\")\n",
    "            return\n",
    "        start_epoch = step // len(train_loader)\n",
    "    else:\n",
    "        step = 0\n",
    "        min_eval_loss = np.inf\n",
    "        start_epoch = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch+1, args.max_epochs+1):\n",
    "        pbar = tqdm(train_loader)\n",
    "        skip_steps = step % len(train_loader)  # only used for starting from checkpoints\n",
    "\n",
    "        for idx, batch in enumerate(pbar):\n",
    "            if idx < skip_steps:\n",
    "                continue\n",
    "\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(args.device).long()\n",
    "            attention_mask = batch['attention_mask'].to(args.device)\n",
    "            labels = batch['labels'].to(args.device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            pbar.set_description(\"Epoch {}, Loss {:.3f}\".format(epoch, loss.item()))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            step += 1\n",
    "            if step % args.log_steps == 0:\n",
    "                wandb.log({\"train/loss\": loss.item(), 'optim/lr': optim.param_groups[0]['lr']}, step=step)\n",
    "\n",
    "            if step % args.eval_steps == 0:\n",
    "                eval_loss = eval(step, args, model, valid_loader)\n",
    "                wandb.log({\"eval/loss\": eval_loss}, step=step)\n",
    "\n",
    "                to_save = {\n",
    "                    'step': step,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optim.state_dict(),\n",
    "                    'eval_loss': eval_loss,\n",
    "                    'min_eval_loss': min_eval_loss,\n",
    "                }\n",
    "\n",
    "                save_path = os.path.join(args.ckpt_dir, f\"model-{step}.pt\")\n",
    "                torch.save(to_save, save_path)\n",
    "                print(\"=> Save checkpoint to '{}' (step {})\".format(save_path, step))\n",
    "\n",
    "                if eval_loss < min_eval_loss:\n",
    "                    min_eval_loss = eval_loss\n",
    "                    save_path = os.path.join(args.ckpt_dir, \"model-best.pt\")\n",
    "                    torch.save(to_save, save_path)\n",
    "                    print(\"=> Save checkpoint to '{}' (step {})\".format(save_path, step))\n",
    "\n",
    "                print(\"\\n\")\n",
    "\n",
    "                model.train()\n",
    "\n",
    "    eval_loss = eval(step, args, model, valid_loader)\n",
    "    to_save = {\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'eval_loss': eval_loss,\n",
    "        'min_eval_loss': min_eval_loss,\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(args.ckpt_dir, f\"model-{step}.pt\")\n",
    "    torch.save(to_save, save_path)\n",
    "    print(\"=> Save checkpoint to '{}' (step {})\".format(save_path, step))\n",
    "    print(f\"=> Finished training (step {step})!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bert_finetune) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20744<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/checkpoint/ywu/bert_finetune\\wandb\\run-20210912_152427-bert_finetune\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/checkpoint/ywu/bert_finetune\\wandb\\run-20210912_152427-bert_finetune\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">bert_finetune</strong>: <a href=\"https://wandb.ai/ywu/rate-prediction-BERT/runs/bert_finetune\" target=\"_blank\">https://wandb.ai/ywu/rate-prediction-BERT/runs/bert_finetune</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:bert_finetune). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">bert_finetune</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ywu/rate-prediction-BERT\" target=\"_blank\">https://wandb.ai/ywu/rate-prediction-BERT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ywu/rate-prediction-BERT/runs/bert_finetune\" target=\"_blank\">https://wandb.ai/ywu/rate-prediction-BERT/runs/bert_finetune</a><br/>\n",
       "                Run data is saved locally in <code>/checkpoint/ywu/bert_finetune\\bert_finetune\\wandb\\run-20210912_152517-bert_finetune</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded pretrained model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                           | 0/13334 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/1737682860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinetune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/1932370576.py\u001b[0m in \u001b[0;36mfinetune\u001b[1;34m(args, train_loader, valid_loader, test_loader)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mskip_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# only used for starting from checkpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mskip_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/2005405090.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(sefl, idx)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msefl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "finetune(args,train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rating_prediction_finetuneBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
