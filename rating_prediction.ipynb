{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Using cached flair-0.6.1.post1-py3-none-any.whl (337 kB)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Using cached bpemb-0.3.2-py3-none-any.whl (19 kB)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.8.tar.gz (981 kB)\n",
      "Collecting hyperopt>=0.1.1\n",
      "  Using cached hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: gensim>=3.4.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.8.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (3.2.2)\n",
      "Collecting segtok>=1.5.7\n",
      "  Using cached segtok-1.5.10.tar.gz (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Using cached konoha-4.6.2-py3-none-any.whl (19 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.94-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: regex in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (2020.6.8)\n",
      "Collecting mpld3==0.3\n",
      "  Using cached mpld3-0.3.tar.gz (788 kB)\n",
      "Collecting gdown\n",
      "  Using cached gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (4.5.2)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-5.8.tar.gz (64 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (4.47.0)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Using cached sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from flair) (0.23.1)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting transformers>=3.0.0\n",
      "  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "Collecting janome\n",
      "  Using cached Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.18.5)\n",
      "Requirement already satisfied: requests in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from bpemb>=0.3.2->flair) (2.24.0)\n",
      "Requirement already satisfied: six in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from langdetect->flair) (1.15.0)\n",
      "Requirement already satisfied: future in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (0.29.14)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (3.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Collecting overrides==3.0.0\n",
      "  Downloading overrides-3.0.0.tar.gz (4.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from gdown->flair) (3.0.12)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from torch>=1.1.0->flair) (3.7.4.2)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (20.4)\n",
      "Collecting tokenizers==0.9.3\n",
      "  Downloading tokenizers-0.9.3-cp38-cp38-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->flair) (3.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
      "Building wheels for collected packages: langdetect, segtok, mpld3, gdown, ftfy, sqlitedict, overrides, sacremoses\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993196 sha256=2d46b4cd710014c763200dd65879e5d3aca9e51392a6a78ed1a9df8e408011f6\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\1e\\80\\23\\0a24928ec3a3906ff5027f38d2fea824e7e97f2ba7c83d91e3\n",
      "  Building wheel for segtok (setup.py): started\n",
      "  Building wheel for segtok (setup.py): finished with status 'done'\n",
      "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25022 sha256=75656c3cb411c0b2a63e9e86f65e9c34e6890eb02b6350a52e9d79074baebb0c\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\36\\6d\\90\\6d9b11ba404f68f340ef3f6060cfdf9c9f34653b08eceeacf6\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116682 sha256=a1dcb34695e0b23c7f692b69c4aca101e7e47a74c14d0df676770a7b4d9880cc\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\3d\\9f\\9d\\d806a20bd97bc7076d724fa3e69fa5be61836ba16b2ffa6126\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9684 sha256=e2c9618d1f8ea39984241139a4088dfd09c6a4e5cbd2f6545472dda0e8d2f6dc\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\e2\\62\\1e\\926d1ebe7b1e733c78d627fd288d01b83feaf67efc06e0e4c3\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-5.8-py3-none-any.whl size=45617 sha256=26bc2fc19cde1096bb0acd89ebf75f6dfd8b3adc22fdca61d38ad7b5955a9132\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\3f\\a5\\65\\684a672b6a26cb8ce3934d155c98d0e23b3dce3d2c0fadae19\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14381 sha256=a0df75129e5cb57b298f7b369a651aad79aae921bdb0d8f8862038125ae11471\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\92\\82\\8c\\54ef8d8770fd1a80938197e55d3ccd26eccd117f44c58f601b\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.0.0-py3-none-any.whl size=5674 sha256=cd6cc3ec589aeaef21a3ff195e5ce5aa2832828774484ab00be0b92d4d9c22e6\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\4a\\62\\c2\\1a021999d160fce8988607bcd416f1da7a494b476ef3ce59a7\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893262 sha256=7b34478e0196d2389ba233b2f9a87a4d5113b9e124a1eb96b094aa472d588ee9\n",
      "  Stored in directory: c:\\users\\kevinzhenshuai\\appdata\\local\\pip\\cache\\wheels\\7b\\78\\f4\\27d43a65043e1b75dbddaa421b573eddc67e712be4b1c80677\n",
      "Successfully built langdetect segtok mpld3 gdown ftfy sqlitedict overrides sacremoses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "transformers 3.5.1 requires sentencepiece==0.1.91, but you'll have sentencepiece 0.1.94 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: sentencepiece, bpemb, langdetect, hyperopt, segtok, tabulate, overrides, konoha, mpld3, gdown, ftfy, sqlitedict, deprecated, sacremoses, tokenizers, transformers, janome, flair, dataclasses\n",
      "  Attempting uninstall: mpld3\n",
      "    Found existing installation: mpld3 0.5.1\n",
      "    Uninstalling mpld3-0.5.1:\n",
      "      Successfully uninstalled mpld3-0.5.1\n",
      "Successfully installed bpemb-0.3.2 dataclasses-0.6 deprecated-1.2.10 flair-0.6.1.post1 ftfy-5.8 gdown-3.12.2 hyperopt-0.2.5 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.94 sqlitedict-1.7.0 tabulate-0.8.7 tokenizers-0.9.3 transformers-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: keras in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (2.4.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\kevinzhenshuai\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import html\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings, WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix, coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Reading JSON file which contains multiple JSON document\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   overall         200000 non-null  float64\n",
      " 1   reviewTime      200000 non-null  object \n",
      " 2   reviewerID      200000 non-null  object \n",
      " 3   reviewText      199964 non-null  object \n",
      " 4   summary         199965 non-null  object \n",
      " 5   unixReviewTime  200000 non-null  int64  \n",
      " 6   category        200000 non-null  object \n",
      " 7   price           200000 non-null  object \n",
      " 8   itemID          200000 non-null  object \n",
      " 9   reviewHash      200000 non-null  object \n",
      " 10  image           463 non-null     object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 16.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>08 24, 2010</td>\n",
       "      <td>u04428712</td>\n",
       "      <td>So is Katy Perry's new album \"Teenage Dream\" c...</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$35.93</td>\n",
       "      <td>p70761125</td>\n",
       "      <td>85559980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 31, 2009</td>\n",
       "      <td>u06946603</td>\n",
       "      <td>I got this CD almost 10 years ago, and given t...</td>\n",
       "      <td>Excellent album</td>\n",
       "      <td>1256947200</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.28</td>\n",
       "      <td>p85427891</td>\n",
       "      <td>41699565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 13, 2015</td>\n",
       "      <td>u92735614</td>\n",
       "      <td>I REALLY enjoy this pairing of Anderson and Po...</td>\n",
       "      <td>Love the Music, Hate the Light Show</td>\n",
       "      <td>1444694400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$89.86</td>\n",
       "      <td>p82172532</td>\n",
       "      <td>24751194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 28, 2017</td>\n",
       "      <td>u35112935</td>\n",
       "      <td>Finally got it . It was everything thought it ...</td>\n",
       "      <td>Great</td>\n",
       "      <td>1498608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.89</td>\n",
       "      <td>p15255251</td>\n",
       "      <td>22820631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>u07141505</td>\n",
       "      <td>Look at all star cast.  Outstanding record, pl...</td>\n",
       "      <td>Love these guys.</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>p82618188</td>\n",
       "      <td>53377470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall   reviewTime reviewerID  \\\n",
       "0      4.0  08 24, 2010  u04428712   \n",
       "1      5.0  10 31, 2009  u06946603   \n",
       "2      4.0  10 13, 2015  u92735614   \n",
       "3      5.0  06 28, 2017  u35112935   \n",
       "4      4.0  10 12, 2015  u07141505   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  So is Katy Perry's new album \"Teenage Dream\" c...   \n",
       "1  I got this CD almost 10 years ago, and given t...   \n",
       "2  I REALLY enjoy this pairing of Anderson and Po...   \n",
       "3  Finally got it . It was everything thought it ...   \n",
       "4  Look at all star cast.  Outstanding record, pl...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0  Amazing that I Actually Bought This...More Ama...      1282608000   \n",
       "1                                    Excellent album      1256947200   \n",
       "2                Love the Music, Hate the Light Show      1444694400   \n",
       "3                                              Great      1498608000   \n",
       "4                                   Love these guys.      1444608000   \n",
       "\n",
       "           category   price     itemID reviewHash image  \n",
       "0               Pop  $35.93  p70761125   85559980   NaN  \n",
       "1  Alternative Rock  $11.28  p85427891   41699565   NaN  \n",
       "2               Pop  $89.86  p82172532   24751194   NaN  \n",
       "3               Pop  $11.89  p15255251   22820631   NaN  \n",
       "4              Jazz  $15.24  p82618188   53377470   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainList = []\n",
    "print(\"Started Reading JSON file which contains multiple JSON document\")\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    for jsonObj in f:\n",
    "        trainDict = json.loads(jsonObj)\n",
    "        trainList.append(trainDict)\n",
    "        \n",
    "trainDF = pd.DataFrame(data = trainList)\n",
    "trainDF.info()\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Reading JSON file which contains multiple JSON document\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reviewTime      10000 non-null  object\n",
      " 1   reviewerID      10000 non-null  object\n",
      " 2   reviewText      9999 non-null   object\n",
      " 3   summary         9998 non-null   object\n",
      " 4   unixReviewTime  10000 non-null  int64 \n",
      " 5   category        10000 non-null  object\n",
      " 6   price           10000 non-null  object\n",
      " 7   itemID          10000 non-null  object\n",
      " 8   reviewHash      10000 non-null  object\n",
      " 9   image           23 non-null     object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03 26, 2015</td>\n",
       "      <td>u32476110</td>\n",
       "      <td>Fantastic mix of \"old school\" with a creative ...</td>\n",
       "      <td>Fantastic mix of \"old school\" with a creative ...</td>\n",
       "      <td>1427328000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$14.98</td>\n",
       "      <td>p76243483</td>\n",
       "      <td>20167847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05 15, 2017</td>\n",
       "      <td>u36732410</td>\n",
       "      <td>Update: Indications\\nThere are various opinion...</td>\n",
       "      <td>Digitally Extracted Stereo (DES) Rules!</td>\n",
       "      <td>1494806400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$15.16</td>\n",
       "      <td>p92485419</td>\n",
       "      <td>30527605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06 4, 2015</td>\n",
       "      <td>u85385007</td>\n",
       "      <td>This album provides a new twist on old Sammy H...</td>\n",
       "      <td>Excellent unplugged album</td>\n",
       "      <td>1433376000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$7.37</td>\n",
       "      <td>p40031588</td>\n",
       "      <td>12169432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04 23, 2009</td>\n",
       "      <td>u30715529</td>\n",
       "      <td>(Symbol) can be considered as another masterpi...</td>\n",
       "      <td>another masterpiece</td>\n",
       "      <td>1240444800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$12.45</td>\n",
       "      <td>p88719785</td>\n",
       "      <td>55648615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09 15, 2000</td>\n",
       "      <td>u95909892</td>\n",
       "      <td>Many would think this album is good only becau...</td>\n",
       "      <td>True Classic Rock</td>\n",
       "      <td>968976000</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$2.07</td>\n",
       "      <td>p59188380</td>\n",
       "      <td>09520938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewTime reviewerID                                         reviewText  \\\n",
       "0  03 26, 2015  u32476110  Fantastic mix of \"old school\" with a creative ...   \n",
       "1  05 15, 2017  u36732410  Update: Indications\\nThere are various opinion...   \n",
       "2   06 4, 2015  u85385007  This album provides a new twist on old Sammy H...   \n",
       "3  04 23, 2009  u30715529  (Symbol) can be considered as another masterpi...   \n",
       "4  09 15, 2000  u95909892  Many would think this album is good only becau...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0  Fantastic mix of \"old school\" with a creative ...      1427328000   \n",
       "1            Digitally Extracted Stereo (DES) Rules!      1494806400   \n",
       "2                          Excellent unplugged album      1433376000   \n",
       "3                                another masterpiece      1240444800   \n",
       "4                                  True Classic Rock       968976000   \n",
       "\n",
       "           category   price     itemID reviewHash image  \n",
       "0               Pop  $14.98  p76243483   20167847   NaN  \n",
       "1               Pop  $15.16  p92485419   30527605   NaN  \n",
       "2               Pop   $7.37  p40031588   12169432   NaN  \n",
       "3               Pop  $12.45  p88719785   55648615   NaN  \n",
       "4  Alternative Rock   $2.07  p59188380   09520938   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testList = []\n",
    "print(\"Started Reading JSON file which contains multiple JSON document\")\n",
    "with open(\"test.json\", \"r\") as f:\n",
    "    for jsonObj in f:\n",
    "        testDict = json.loads(jsonObj)\n",
    "        testList.append(testDict)\n",
    "        \n",
    "testDF = pd.DataFrame(data = testList)\n",
    "testDF.info()\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_escaping(text):\n",
    "    '''html escaping: Html character codes (i.e., &...;) are replaced with an ASCII equivalent'''\n",
    "    return html.unescape(text)\n",
    "\n",
    "def to_lower(text):\n",
    "    '''lower case all words in text'''\n",
    "    return text.lower()\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    '''remove urls'''\n",
    "    return re.sub(r\"http\\S+\", ' ', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    '''Remove punctuation from text'''\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "def denoise_text(text):\n",
    "    text = str(text) # make sure all inputs are type string\n",
    "    text = to_lower(text)\n",
    "    text = strip_html(text)\n",
    "    text = html_escaping(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and normalize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_extraction(text):    \n",
    "    '''removing stopwords from the sentence and tokenize the sentence'''\n",
    "    stopWords = stopwords.words('english')\n",
    "    # append words with puncutations stripped\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in stopWords]\n",
    "    stopWords.extend(stripped)\n",
    "    # remove duplicates for runtime\n",
    "    stopWords= list(dict.fromkeys(stopWords))\n",
    "    \n",
    "    ignore = stopWords   \n",
    "    words = re.sub(\"[^\\w]\", \" \",  text).split()    \n",
    "    cleaned_words = [w for w in words if w not in ignore]    \n",
    "    return cleaned_words\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def detokenize_text(words):\n",
    "    '''detokenize words into a text string'''\n",
    "    return ' '.join(words)\n",
    "\n",
    "def normalize_text(text):\n",
    "    words = word_extraction(text)\n",
    "    #words = lemmatize_verbs(words)\n",
    "    words = stem_words(words)\n",
    "    text = detokenize_text(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unixReviewTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekday(unixTime):\n",
    "    '''Extact Weekday as localeâ€™s abbreviated name from unixReviewTime as the feature'''\n",
    "    return datetime.fromtimestamp(unixTime, timezone.utc).strftime(\"%A\")\n",
    "\n",
    "def get_year(unixTime):\n",
    "    return int(datetime.fromtimestamp(unixTime,timezone.utc).strftime('%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['weekday'] = trainDF['unixReviewTime'].apply(lambda x: get_weekday(x))\n",
    "trainDF['year'] = trainDF['unixReviewTime'].apply(lambda x: get_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST -------------------------------------------------------\n",
    "testDF['weekday'] = testDF['unixReviewTime'].apply(lambda x: get_weekday(x))\n",
    "testDF['year'] = testDF['unixReviewTime'].apply(lambda x: get_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuesday      32180\n",
       "Wednesday    29868\n",
       "Monday       29066\n",
       "Thursday     28796\n",
       "Friday       28243\n",
       "Saturday     26427\n",
       "Sunday       25420\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['weekday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuesday      1655\n",
       "Wednesday    1524\n",
       "Friday       1433\n",
       "Thursday     1413\n",
       "Monday       1412\n",
       "Saturday     1316\n",
       "Sunday       1247\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['weekday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['price'] = trainDF['price'].str.replace('$', '')\n",
    "trainDF['price'] = trainDF['price'].apply(lambda x : pd.to_numeric(x,errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5ZZzLvgMzojy",
    "outputId": "544c33c6-9873-4f42-877b-7d9222aadbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Alldata  NaN Price     ratio\n",
      "Alternative Rock    0.283790   0.357012  1.258015\n",
      "Classical           0.094275   0.082754  0.877789\n",
      "Dance & Electronic  0.062630   0.050165  0.800970\n",
      "Jazz                0.098930   0.072867  0.736552\n",
      "Pop                 0.460375   0.437202  0.949666\n"
     ]
    }
   ],
   "source": [
    "# There are several methods to determine how to handle NaN values \n",
    "#- including dropping them, filling with mode or mean, or replacing with an \"Other\" value\n",
    "# start with data exploration - can check if there a pattern in where the NaN values appear or if the rows with NaN are randomly distributed\n",
    "\n",
    "# For Example - is the a pattern in job categories where NaN contract type appears or is it similar to the full data set?\n",
    "\n",
    "a = trainDF['category'].value_counts(normalize=True)\n",
    "b = trainDF[trainDF['price'].isnull()]['category'].value_counts(normalize=True)\n",
    "print (pd.DataFrame({'Alldata': a, 'NaN Price':b,'ratio':b/a}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hzYYHjEzzoj0"
   },
   "outputs": [],
   "source": [
    "# fill null price with mode\n",
    "trainDF['price'].fillna(trainDF['price'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF['price'] = testDF['price'].str.replace('$', '')\n",
    "testDF['price'] = testDF['price'].apply(lambda x : pd.to_numeric(x,errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5ZZzLvgMzojy",
    "outputId": "544c33c6-9873-4f42-877b-7d9222aadbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Alldata  NaN Price     ratio\n",
      "Alternative Rock     0.2901   0.349650  1.205275\n",
      "Classical            0.0903   0.083916  0.929303\n",
      "Dance & Electronic   0.0627   0.083916  1.338375\n",
      "Jazz                 0.0993   0.076923  0.774653\n",
      "Pop                  0.4576   0.405594  0.886351\n"
     ]
    }
   ],
   "source": [
    "a = testDF['category'].value_counts(normalize=True)\n",
    "b = testDF[testDF['price'].isnull()]['category'].value_counts(normalize=True)\n",
    "print (pd.DataFrame({'Alldata': a, 'NaN Price':b,'ratio':b/a}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hzYYHjEzzoj0"
   },
   "outputs": [],
   "source": [
    "# fill null price with mode\n",
    "testDF['price'].fillna(testDF['price'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop                   92075\n",
       "Alternative Rock      56758\n",
       "Jazz                  19786\n",
       "Classical             18855\n",
       "Dance & Electronic    12526\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_counts = trainDF.reviewerID.value_counts()\n",
    "value_mask = trainDF.reviewerID.isin(review_counts.index[review_counts < 20])\n",
    "trainDF.loc[value_mask,'reviewerID'] = \"Other\"\n",
    "testDF.loc[testDF.reviewerID.isin(list(review_counts.index[review_counts > 20])) == False,\\\n",
    "                  \"reviewerID\"] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.get_dummies(data=trainDF, columns=[\"reviewerID\",'weekday','category'])\n",
    "testDF = pd.get_dummies(data=testDF, columns=[\"reviewerID\",'weekday','category'])\n",
    "\n",
    "\n",
    "# In case there are missing columns in Test\n",
    "missing_cols = set( trainDF.columns ) - set(testDF.columns )\n",
    "for column in missing_cols:\n",
    "    testDF[column] = 0\n",
    "testDF = testDF[trainDF.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP on text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/b003hjwjy6?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    katy perry new alb teen dream cont der unorigi...\n",
       "1    got cd almost 10 year ago giv pass tim stil th...\n",
       "2    real enjoy pair anderson ponty mus much would ...\n",
       "3                fin got everyth thought would gre mus\n",
       "4    look star cast outstand record play impress 4 ...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['reviewText'] = trainDF['reviewText'].apply(lambda x: denoise_text(x)) \n",
    "trainDF['reviewText'] = trainDF['reviewText'].apply(lambda x: normalize_text(x)) \n",
    "trainDF['reviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['reviewText'] = trainDF['reviewText'].apply(lambda x: 'unknown' if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>category_Alternative Rock</th>\n",
       "      <th>category_Classical</th>\n",
       "      <th>category_Dance &amp; Electronic</th>\n",
       "      <th>category_Jazz</th>\n",
       "      <th>category_Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>5.0</td>\n",
       "      <td>05 3, 2018</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1525305600</td>\n",
       "      <td>14.99</td>\n",
       "      <td>p51175958</td>\n",
       "      <td>77435483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12 23, 2014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1419292800</td>\n",
       "      <td>18.82</td>\n",
       "      <td>p62233954</td>\n",
       "      <td>47305192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 26, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1424908800</td>\n",
       "      <td>12.98</td>\n",
       "      <td>p36840459</td>\n",
       "      <td>82555669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>3.0</td>\n",
       "      <td>04 24, 2018</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1524528000</td>\n",
       "      <td>11.99</td>\n",
       "      <td>p12318999</td>\n",
       "      <td>62207941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>4.0</td>\n",
       "      <td>06 1, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Classic Tina...</td>\n",
       "      <td>1496275200</td>\n",
       "      <td>14.57</td>\n",
       "      <td>p24847185</td>\n",
       "      <td>74826717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196797</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 9, 2014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1404864000</td>\n",
       "      <td>10.04</td>\n",
       "      <td>p01993249</td>\n",
       "      <td>68055384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198588</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 12, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1452556800</td>\n",
       "      <td>18.98</td>\n",
       "      <td>p41783190</td>\n",
       "      <td>38135696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198606</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 9, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1486598400</td>\n",
       "      <td>13.98</td>\n",
       "      <td>p23085153</td>\n",
       "      <td>57943989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198630</th>\n",
       "      <td>5.0</td>\n",
       "      <td>09 28, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1506556800</td>\n",
       "      <td>14.39</td>\n",
       "      <td>p98744367</td>\n",
       "      <td>68660574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199855</th>\n",
       "      <td>5.0</td>\n",
       "      <td>05 31, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1464652800</td>\n",
       "      <td>12.07</td>\n",
       "      <td>p76579667</td>\n",
       "      <td>97164785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall   reviewTime reviewText          summary  unixReviewTime  \\\n",
       "542         5.0   05 3, 2018    unknown       Five Stars      1525305600   \n",
       "876         4.0  12 23, 2014    unknown       Four Stars      1419292800   \n",
       "923         5.0  02 26, 2015    unknown       Five Stars      1424908800   \n",
       "5411        3.0  04 24, 2018    unknown      Three Stars      1524528000   \n",
       "7409        4.0   06 1, 2017    unknown  Classic Tina...      1496275200   \n",
       "...         ...          ...        ...              ...             ...   \n",
       "196797      5.0   07 9, 2014    unknown       Five Stars      1404864000   \n",
       "198588      5.0  01 12, 2016    unknown       Five Stars      1452556800   \n",
       "198606      5.0   02 9, 2017    unknown       Five Stars      1486598400   \n",
       "198630      5.0  09 28, 2017    unknown       Five Stars      1506556800   \n",
       "199855      5.0  05 31, 2016    unknown       Five Stars      1464652800   \n",
       "\n",
       "        price     itemID reviewHash image  year  ...  weekday_Saturday  \\\n",
       "542     14.99  p51175958   77435483   NaN  2018  ...                 0   \n",
       "876     18.82  p62233954   47305192   NaN  2014  ...                 0   \n",
       "923     12.98  p36840459   82555669   NaN  2015  ...                 0   \n",
       "5411    11.99  p12318999   62207941   NaN  2018  ...                 0   \n",
       "7409    14.57  p24847185   74826717   NaN  2017  ...                 0   \n",
       "...       ...        ...        ...   ...   ...  ...               ...   \n",
       "196797  10.04  p01993249   68055384   NaN  2014  ...                 0   \n",
       "198588  18.98  p41783190   38135696   NaN  2016  ...                 0   \n",
       "198606  13.98  p23085153   57943989   NaN  2017  ...                 0   \n",
       "198630  14.39  p98744367   68660574   NaN  2017  ...                 0   \n",
       "199855  12.07  p76579667   97164785   NaN  2016  ...                 0   \n",
       "\n",
       "        weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
       "542                  0                 1                0                  0   \n",
       "876                  0                 0                1                  0   \n",
       "923                  0                 1                0                  0   \n",
       "5411                 0                 0                1                  0   \n",
       "7409                 0                 1                0                  0   \n",
       "...                ...               ...              ...                ...   \n",
       "196797               0                 0                0                  1   \n",
       "198588               0                 0                1                  0   \n",
       "198606               0                 1                0                  0   \n",
       "198630               0                 1                0                  0   \n",
       "199855               0                 0                1                  0   \n",
       "\n",
       "        category_Alternative Rock  category_Classical  \\\n",
       "542                             0                   0   \n",
       "876                             1                   0   \n",
       "923                             0                   0   \n",
       "5411                            0                   0   \n",
       "7409                            0                   0   \n",
       "...                           ...                 ...   \n",
       "196797                          1                   0   \n",
       "198588                          0                   1   \n",
       "198606                          0                   0   \n",
       "198630                          0                   1   \n",
       "199855                          0                   0   \n",
       "\n",
       "        category_Dance & Electronic  category_Jazz  category_Pop  \n",
       "542                               0              0             1  \n",
       "876                               0              0             0  \n",
       "923                               0              1             0  \n",
       "5411                              0              0             1  \n",
       "7409                              0              0             1  \n",
       "...                             ...            ...           ...  \n",
       "196797                            0              0             0  \n",
       "198588                            0              0             0  \n",
       "198606                            0              0             1  \n",
       "198630                            0              0             0  \n",
       "199855                            0              1             0  \n",
       "\n",
       "[284 rows x 672 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.loc[trainDF['reviewText'] == 'unknown'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:414: MarkupResemblesLocatorWarning: \"http://www.amazon.com/jackrabbit-san-fermin/dp/b00tbbaryi?ie=utf8&redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_9\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>category_Alternative Rock</th>\n",
       "      <th>category_Classical</th>\n",
       "      <th>category_Dance &amp; Electronic</th>\n",
       "      <th>category_Jazz</th>\n",
       "      <th>category_Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03 26, 2015</td>\n",
       "      <td>fantast mix old school cre new sound heard sim...</td>\n",
       "      <td>Fantastic mix of \"old school\" with a creative ...</td>\n",
       "      <td>1427328000</td>\n",
       "      <td>14.98</td>\n",
       "      <td>p76243483</td>\n",
       "      <td>20167847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>05 15, 2017</td>\n",
       "      <td>upd ind vary opin regard mono vers stereo bott...</td>\n",
       "      <td>Digitally Extracted Stereo (DES) Rules!</td>\n",
       "      <td>1494806400</td>\n",
       "      <td>15.16</td>\n",
       "      <td>p92485419</td>\n",
       "      <td>30527605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>06 4, 2015</td>\n",
       "      <td>alb provid new twist old sammy hag van hal son...</td>\n",
       "      <td>Excellent unplugged album</td>\n",
       "      <td>1433376000</td>\n",
       "      <td>7.37</td>\n",
       "      <td>p40031588</td>\n",
       "      <td>12169432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>04 23, 2009</td>\n",
       "      <td>symbol consid anoth masterpiec print put fanta...</td>\n",
       "      <td>another masterpiece</td>\n",
       "      <td>1240444800</td>\n",
       "      <td>12.45</td>\n",
       "      <td>p88719785</td>\n",
       "      <td>55648615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>09 15, 2000</td>\n",
       "      <td>many would think alb good get would wrong asse...</td>\n",
       "      <td>True Classic Rock</td>\n",
       "      <td>968976000</td>\n",
       "      <td>2.07</td>\n",
       "      <td>p59188380</td>\n",
       "      <td>09520938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall   reviewTime                                         reviewText  \\\n",
       "0        0  03 26, 2015  fantast mix old school cre new sound heard sim...   \n",
       "1        0  05 15, 2017  upd ind vary opin regard mono vers stereo bott...   \n",
       "2        0   06 4, 2015  alb provid new twist old sammy hag van hal son...   \n",
       "3        0  04 23, 2009  symbol consid anoth masterpiec print put fanta...   \n",
       "4        0  09 15, 2000  many would think alb good get would wrong asse...   \n",
       "\n",
       "                                             summary  unixReviewTime  price  \\\n",
       "0  Fantastic mix of \"old school\" with a creative ...      1427328000  14.98   \n",
       "1            Digitally Extracted Stereo (DES) Rules!      1494806400  15.16   \n",
       "2                          Excellent unplugged album      1433376000   7.37   \n",
       "3                                another masterpiece      1240444800  12.45   \n",
       "4                                  True Classic Rock       968976000   2.07   \n",
       "\n",
       "      itemID reviewHash image  year  ...  weekday_Saturday  weekday_Sunday  \\\n",
       "0  p76243483   20167847   NaN  2015  ...                 0               0   \n",
       "1  p92485419   30527605   NaN  2017  ...                 0               0   \n",
       "2  p40031588   12169432   NaN  2015  ...                 0               0   \n",
       "3  p88719785   55648615   NaN  2009  ...                 0               0   \n",
       "4  p59188380   09520938   NaN  2000  ...                 0               0   \n",
       "\n",
       "   weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
       "0                 1                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 1                0                  0   \n",
       "3                 1                0                  0   \n",
       "4                 0                0                  0   \n",
       "\n",
       "   category_Alternative Rock  category_Classical  category_Dance & Electronic  \\\n",
       "0                          0                   0                            0   \n",
       "1                          0                   0                            0   \n",
       "2                          0                   0                            0   \n",
       "3                          0                   0                            0   \n",
       "4                          1                   0                            0   \n",
       "\n",
       "   category_Jazz  category_Pop  \n",
       "0              0             1  \n",
       "1              0             1  \n",
       "2              0             1  \n",
       "3              0             1  \n",
       "4              0             0  \n",
       "\n",
       "[5 rows x 672 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "testDF['reviewText'] = testDF['reviewText'].apply(lambda x: denoise_text(x)) \n",
    "testDF['reviewText'] = testDF['reviewText'].apply(lambda x: normalize_text(x)) \n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF['reviewText'] = testDF['reviewText'].apply(lambda x: 'unknown' if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>category_Alternative Rock</th>\n",
       "      <th>category_Classical</th>\n",
       "      <th>category_Dance &amp; Electronic</th>\n",
       "      <th>category_Jazz</th>\n",
       "      <th>category_Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>01 30, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1485734400</td>\n",
       "      <td>11.94</td>\n",
       "      <td>p84457806</td>\n",
       "      <td>59392884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>06 13, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1465776000</td>\n",
       "      <td>9.68</td>\n",
       "      <td>p51656766</td>\n",
       "      <td>03839526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>05 3, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1493769600</td>\n",
       "      <td>15.16</td>\n",
       "      <td>p92485419</td>\n",
       "      <td>46674136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0</td>\n",
       "      <td>08 25, 2003</td>\n",
       "      <td>unknown</td>\n",
       "      <td>No, No, No, etc.</td>\n",
       "      <td>1061769600</td>\n",
       "      <td>8.98</td>\n",
       "      <td>p90041047</td>\n",
       "      <td>26513936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0</td>\n",
       "      <td>04 10, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1428624000</td>\n",
       "      <td>30.75</td>\n",
       "      <td>p53702411</td>\n",
       "      <td>12005050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>4.11</td>\n",
       "      <td>p33589931</td>\n",
       "      <td>02044535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>04 29, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1430265600</td>\n",
       "      <td>11.66</td>\n",
       "      <td>p44060712</td>\n",
       "      <td>07344599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>08 4, 2014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Great album from Anberlin</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>14.90</td>\n",
       "      <td>p03021942</td>\n",
       "      <td>40666447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>0</td>\n",
       "      <td>04 19, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1429401600</td>\n",
       "      <td>16.76</td>\n",
       "      <td>p18504647</td>\n",
       "      <td>67902365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>0</td>\n",
       "      <td>09 9, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441756800</td>\n",
       "      <td>13.40</td>\n",
       "      <td>p31593118</td>\n",
       "      <td>35395914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>0</td>\n",
       "      <td>12 26, 2014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1419552000</td>\n",
       "      <td>6.14</td>\n",
       "      <td>p52587380</td>\n",
       "      <td>71724208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>0</td>\n",
       "      <td>12 14, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>The Police</td>\n",
       "      <td>1513209600</td>\n",
       "      <td>19.48</td>\n",
       "      <td>p17258347</td>\n",
       "      <td>46614864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0</td>\n",
       "      <td>06 11, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1433980800</td>\n",
       "      <td>22.99</td>\n",
       "      <td>p87838918</td>\n",
       "      <td>70929156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>0</td>\n",
       "      <td>05 4, 2018</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1525392000</td>\n",
       "      <td>11.99</td>\n",
       "      <td>p80821798</td>\n",
       "      <td>44987127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>0</td>\n",
       "      <td>03 21, 2017</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1490054400</td>\n",
       "      <td>16.28</td>\n",
       "      <td>p18475994</td>\n",
       "      <td>50705354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>0</td>\n",
       "      <td>02 10, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1423526400</td>\n",
       "      <td>9.50</td>\n",
       "      <td>p53694011</td>\n",
       "      <td>86755458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>0</td>\n",
       "      <td>10 23, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1477180800</td>\n",
       "      <td>9.99</td>\n",
       "      <td>p80142967</td>\n",
       "      <td>11921209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>0</td>\n",
       "      <td>02 2, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1422835200</td>\n",
       "      <td>12.55</td>\n",
       "      <td>p57715905</td>\n",
       "      <td>04095256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>0</td>\n",
       "      <td>02 20, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>A+</td>\n",
       "      <td>1424390400</td>\n",
       "      <td>12.29</td>\n",
       "      <td>p06680392</td>\n",
       "      <td>83329677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>0</td>\n",
       "      <td>08 30, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1440892800</td>\n",
       "      <td>32.69</td>\n",
       "      <td>p81263881</td>\n",
       "      <td>87002784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>0</td>\n",
       "      <td>11 25, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1480032000</td>\n",
       "      <td>17.22</td>\n",
       "      <td>p28333095</td>\n",
       "      <td>86171291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>0</td>\n",
       "      <td>02 1, 2018</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1517443200</td>\n",
       "      <td>11.99</td>\n",
       "      <td>p82332368</td>\n",
       "      <td>82048478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>0</td>\n",
       "      <td>11 23, 2016</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1479859200</td>\n",
       "      <td>9.48</td>\n",
       "      <td>p15450904</td>\n",
       "      <td>22913378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall   reviewTime reviewText                    summary  \\\n",
       "132         0  01 30, 2017    unknown                 Five Stars   \n",
       "448         0  06 13, 2016    unknown                 Five Stars   \n",
       "799         0   05 3, 2017    unknown                 Five Stars   \n",
       "983         0  08 25, 2003    unknown           No, No, No, etc.   \n",
       "1455        0  04 10, 2015    unknown                 Five Stars   \n",
       "1996        0  10 12, 2015    unknown                 Five Stars   \n",
       "2144        0  04 29, 2015    unknown                 Five Stars   \n",
       "3820        0   08 4, 2014    unknown  Great album from Anberlin   \n",
       "3839        0  04 19, 2015    unknown                 Five Stars   \n",
       "4122        0   09 9, 2015    unknown                 Five Stars   \n",
       "4206        0  12 26, 2014    unknown                 Five Stars   \n",
       "4219        0  12 14, 2017    unknown                 The Police   \n",
       "4384        0  06 11, 2015    unknown                 Five Stars   \n",
       "5326        0   05 4, 2018    unknown                 Five Stars   \n",
       "6098        0  03 21, 2017    unknown                 Five Stars   \n",
       "6134        0  02 10, 2015    unknown                 Five Stars   \n",
       "6688        0  10 23, 2016    unknown                 Five Stars   \n",
       "6956        0   02 2, 2015    unknown                 Five Stars   \n",
       "8340        0  02 20, 2015    unknown                         A+   \n",
       "8365        0  08 30, 2015    unknown                Three Stars   \n",
       "8737        0  11 25, 2016    unknown                 Five Stars   \n",
       "9333        0   02 1, 2018    unknown                 Five Stars   \n",
       "9693        0  11 23, 2016    unknown                 Five Stars   \n",
       "\n",
       "      unixReviewTime  price     itemID reviewHash image  year  ...  \\\n",
       "132       1485734400  11.94  p84457806   59392884   NaN  2017  ...   \n",
       "448       1465776000   9.68  p51656766   03839526   NaN  2016  ...   \n",
       "799       1493769600  15.16  p92485419   46674136   NaN  2017  ...   \n",
       "983       1061769600   8.98  p90041047   26513936   NaN  2003  ...   \n",
       "1455      1428624000  30.75  p53702411   12005050   NaN  2015  ...   \n",
       "1996      1444608000   4.11  p33589931   02044535   NaN  2015  ...   \n",
       "2144      1430265600  11.66  p44060712   07344599   NaN  2015  ...   \n",
       "3820      1407110400  14.90  p03021942   40666447   NaN  2014  ...   \n",
       "3839      1429401600  16.76  p18504647   67902365   NaN  2015  ...   \n",
       "4122      1441756800  13.40  p31593118   35395914   NaN  2015  ...   \n",
       "4206      1419552000   6.14  p52587380   71724208   NaN  2014  ...   \n",
       "4219      1513209600  19.48  p17258347   46614864   NaN  2017  ...   \n",
       "4384      1433980800  22.99  p87838918   70929156   NaN  2015  ...   \n",
       "5326      1525392000  11.99  p80821798   44987127   NaN  2018  ...   \n",
       "6098      1490054400  16.28  p18475994   50705354   NaN  2017  ...   \n",
       "6134      1423526400   9.50  p53694011   86755458   NaN  2015  ...   \n",
       "6688      1477180800   9.99  p80142967   11921209   NaN  2016  ...   \n",
       "6956      1422835200  12.55  p57715905   04095256   NaN  2015  ...   \n",
       "8340      1424390400  12.29  p06680392   83329677   NaN  2015  ...   \n",
       "8365      1440892800  32.69  p81263881   87002784   NaN  2015  ...   \n",
       "8737      1480032000  17.22  p28333095   86171291   NaN  2016  ...   \n",
       "9333      1517443200  11.99  p82332368   82048478   NaN  2018  ...   \n",
       "9693      1479859200   9.48  p15450904   22913378   NaN  2016  ...   \n",
       "\n",
       "      weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "132                  0               0                 0                0   \n",
       "448                  0               0                 0                0   \n",
       "799                  0               0                 0                0   \n",
       "983                  0               0                 0                0   \n",
       "1455                 0               0                 0                0   \n",
       "1996                 0               0                 0                0   \n",
       "2144                 0               0                 0                0   \n",
       "3820                 0               0                 0                0   \n",
       "3839                 0               1                 0                0   \n",
       "4122                 0               0                 0                0   \n",
       "4206                 0               0                 0                0   \n",
       "4219                 0               0                 1                0   \n",
       "4384                 0               0                 1                0   \n",
       "5326                 0               0                 0                0   \n",
       "6098                 0               0                 0                1   \n",
       "6134                 0               0                 0                1   \n",
       "6688                 0               1                 0                0   \n",
       "6956                 0               0                 0                0   \n",
       "8340                 0               0                 0                0   \n",
       "8365                 0               1                 0                0   \n",
       "8737                 0               0                 0                0   \n",
       "9333                 0               0                 1                0   \n",
       "9693                 0               0                 0                0   \n",
       "\n",
       "      weekday_Wednesday  category_Alternative Rock  category_Classical  \\\n",
       "132                   0                          0                   0   \n",
       "448                   0                          0                   0   \n",
       "799                   1                          0                   0   \n",
       "983                   0                          0                   0   \n",
       "1455                  0                          0                   0   \n",
       "1996                  0                          0                   0   \n",
       "2144                  1                          1                   0   \n",
       "3820                  0                          1                   0   \n",
       "3839                  0                          1                   0   \n",
       "4122                  1                          0                   0   \n",
       "4206                  0                          1                   0   \n",
       "4219                  0                          1                   0   \n",
       "4384                  0                          1                   0   \n",
       "5326                  0                          0                   0   \n",
       "6098                  0                          0                   0   \n",
       "6134                  0                          0                   0   \n",
       "6688                  0                          1                   0   \n",
       "6956                  0                          0                   0   \n",
       "8340                  0                          0                   0   \n",
       "8365                  0                          0                   0   \n",
       "8737                  0                          0                   0   \n",
       "9333                  0                          1                   0   \n",
       "9693                  1                          0                   0   \n",
       "\n",
       "      category_Dance & Electronic  category_Jazz  category_Pop  \n",
       "132                             0              1             0  \n",
       "448                             0              0             1  \n",
       "799                             0              0             1  \n",
       "983                             0              0             1  \n",
       "1455                            0              1             0  \n",
       "1996                            0              0             1  \n",
       "2144                            0              0             0  \n",
       "3820                            0              0             0  \n",
       "3839                            0              0             0  \n",
       "4122                            0              0             1  \n",
       "4206                            0              0             0  \n",
       "4219                            0              0             0  \n",
       "4384                            0              0             0  \n",
       "5326                            0              0             1  \n",
       "6098                            0              0             1  \n",
       "6134                            0              1             0  \n",
       "6688                            0              0             0  \n",
       "6956                            0              0             1  \n",
       "8340                            0              0             1  \n",
       "8365                            0              0             1  \n",
       "8737                            0              0             1  \n",
       "9333                            0              0             0  \n",
       "9693                            0              0             1  \n",
       "\n",
       "[23 rows x 672 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.loc[testDF['reviewText'] == 'unknown'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".......\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..........\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..//..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \". . . .  .  .  .  .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"....................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \".....................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    amaz act bought thism amaz act lov\n",
       "1                             excel alb\n",
       "2                lov mus hat light show\n",
       "3                                   gre\n",
       "4                               lov guy\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "trainDF['summary'] = trainDF['summary'].apply(lambda x: denoise_text(x)) \n",
    "trainDF['summary'] = trainDF['summary'].apply(lambda x: normalize_text(x))\n",
    "trainDF['summary'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['summary'] = trainDF['summary'].apply(lambda x: 'unknown' if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>category_Alternative Rock</th>\n",
       "      <th>category_Classical</th>\n",
       "      <th>category_Dance &amp; Electronic</th>\n",
       "      <th>category_Jazz</th>\n",
       "      <th>category_Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2.0</td>\n",
       "      <td>05 11, 2016</td>\n",
       "      <td>mus liv expect</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1462924800</td>\n",
       "      <td>13.98</td>\n",
       "      <td>p37967807</td>\n",
       "      <td>28328461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12 1, 2008</td>\n",
       "      <td>say tta us voc cre structured song mislead imm...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1228089600</td>\n",
       "      <td>24.99</td>\n",
       "      <td>p55218454</td>\n",
       "      <td>94891540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11 30, 2011</td>\n",
       "      <td>hat record first bought 1994 stil hat lik list...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1322611200</td>\n",
       "      <td>10.28</td>\n",
       "      <td>p19498936</td>\n",
       "      <td>31739644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 27, 2013</td>\n",
       "      <td>quick acur could ask anyth would go anywh els ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1359244800</td>\n",
       "      <td>11.67</td>\n",
       "      <td>p96637662</td>\n",
       "      <td>72562076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01 21, 2003</td>\n",
       "      <td>cd desecr wond class stick know go back rock rol</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1043107200</td>\n",
       "      <td>6.99</td>\n",
       "      <td>p12955004</td>\n",
       "      <td>83698948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199329</th>\n",
       "      <td>3.0</td>\n",
       "      <td>03 16, 2000</td>\n",
       "      <td>blar guit blurt strange lyr limp bizkit toa me...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>953164800</td>\n",
       "      <td>8.49</td>\n",
       "      <td>p92745515</td>\n",
       "      <td>54391122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199472</th>\n",
       "      <td>5.0</td>\n",
       "      <td>08 5, 2015</td>\n",
       "      <td>ev kind lik jeff beck list ev big fan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>15.16</td>\n",
       "      <td>p89761415</td>\n",
       "      <td>76911336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199512</th>\n",
       "      <td>3.0</td>\n",
       "      <td>02 25, 2006</td>\n",
       "      <td>da su se sci pojavil pre odlicnih bravery soli...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>13.98</td>\n",
       "      <td>p92284858</td>\n",
       "      <td>16002913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199858</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 24, 2011</td>\n",
       "      <td>beat ant bring heat across country sint start ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1295827200</td>\n",
       "      <td>12.99</td>\n",
       "      <td>p72706277</td>\n",
       "      <td>53922793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199924</th>\n",
       "      <td>1.0</td>\n",
       "      <td>04 12, 2010</td>\n",
       "      <td>oh weez go wrong rememb us stick band nam car ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1271030400</td>\n",
       "      <td>11.41</td>\n",
       "      <td>p55134340</td>\n",
       "      <td>24352338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>753 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall   reviewTime  \\\n",
       "520         2.0  05 11, 2016   \n",
       "675         3.0   12 1, 2008   \n",
       "1462        1.0  11 30, 2011   \n",
       "1666        5.0  01 27, 2013   \n",
       "2017        1.0  01 21, 2003   \n",
       "...         ...          ...   \n",
       "199329      3.0  03 16, 2000   \n",
       "199472      5.0   08 5, 2015   \n",
       "199512      3.0  02 25, 2006   \n",
       "199858      5.0  01 24, 2011   \n",
       "199924      1.0  04 12, 2010   \n",
       "\n",
       "                                               reviewText  summary  \\\n",
       "520                                        mus liv expect  unknown   \n",
       "675     say tta us voc cre structured song mislead imm...  unknown   \n",
       "1462    hat record first bought 1994 stil hat lik list...  unknown   \n",
       "1666    quick acur could ask anyth would go anywh els ...  unknown   \n",
       "2017     cd desecr wond class stick know go back rock rol  unknown   \n",
       "...                                                   ...      ...   \n",
       "199329  blar guit blurt strange lyr limp bizkit toa me...  unknown   \n",
       "199472              ev kind lik jeff beck list ev big fan  unknown   \n",
       "199512  da su se sci pojavil pre odlicnih bravery soli...  unknown   \n",
       "199858  beat ant bring heat across country sint start ...  unknown   \n",
       "199924  oh weez go wrong rememb us stick band nam car ...  unknown   \n",
       "\n",
       "        unixReviewTime  price     itemID reviewHash image  year  ...  \\\n",
       "520         1462924800  13.98  p37967807   28328461   NaN  2016  ...   \n",
       "675         1228089600  24.99  p55218454   94891540   NaN  2008  ...   \n",
       "1462        1322611200  10.28  p19498936   31739644   NaN  2011  ...   \n",
       "1666        1359244800  11.67  p96637662   72562076   NaN  2013  ...   \n",
       "2017        1043107200   6.99  p12955004   83698948   NaN  2003  ...   \n",
       "...                ...    ...        ...        ...   ...   ...  ...   \n",
       "199329       953164800   8.49  p92745515   54391122   NaN  2000  ...   \n",
       "199472      1438732800  15.16  p89761415   76911336   NaN  2015  ...   \n",
       "199512      1140825600  13.98  p92284858   16002913   NaN  2006  ...   \n",
       "199858      1295827200  12.99  p72706277   53922793   NaN  2011  ...   \n",
       "199924      1271030400  11.41  p55134340   24352338   NaN  2010  ...   \n",
       "\n",
       "        weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "520                    0               0                 0                0   \n",
       "675                    0               0                 0                0   \n",
       "1462                   0               0                 0                0   \n",
       "1666                   0               1                 0                0   \n",
       "2017                   0               0                 0                1   \n",
       "...                  ...             ...               ...              ...   \n",
       "199329                 0               0                 1                0   \n",
       "199472                 0               0                 0                0   \n",
       "199512                 1               0                 0                0   \n",
       "199858                 0               0                 0                0   \n",
       "199924                 0               0                 0                0   \n",
       "\n",
       "        weekday_Wednesday  category_Alternative Rock  category_Classical  \\\n",
       "520                     1                          0                   0   \n",
       "675                     0                          0                   0   \n",
       "1462                    1                          0                   0   \n",
       "1666                    0                          0                   0   \n",
       "2017                    0                          0                   0   \n",
       "...                   ...                        ...                 ...   \n",
       "199329                  0                          1                   0   \n",
       "199472                  1                          0                   0   \n",
       "199512                  0                          1                   0   \n",
       "199858                  0                          0                   0   \n",
       "199924                  0                          1                   0   \n",
       "\n",
       "        category_Dance & Electronic  category_Jazz  category_Pop  \n",
       "520                               0              0             1  \n",
       "675                               1              0             0  \n",
       "1462                              0              0             1  \n",
       "1666                              0              0             1  \n",
       "2017                              0              0             1  \n",
       "...                             ...            ...           ...  \n",
       "199329                            0              0             0  \n",
       "199472                            0              0             1  \n",
       "199512                            0              0             0  \n",
       "199858                            1              0             0  \n",
       "199924                            0              0             0  \n",
       "\n",
       "[753 rows x 672 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.loc[trainDF['summary'] == 'unknown'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevinzhenshuai\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:329: MarkupResemblesLocatorWarning: \"..................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "testDF['summary'] = testDF['summary'].apply(lambda x: denoise_text(x)) \n",
    "testDF['summary'] = testDF['summary'].apply(lambda x: normalize_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF['summary'] = testDF['summary'].apply(lambda x: 'unknown' if x == '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_Saturday</th>\n",
       "      <th>weekday_Sunday</th>\n",
       "      <th>weekday_Thursday</th>\n",
       "      <th>weekday_Tuesday</th>\n",
       "      <th>weekday_Wednesday</th>\n",
       "      <th>category_Alternative Rock</th>\n",
       "      <th>category_Classical</th>\n",
       "      <th>category_Dance &amp; Electronic</th>\n",
       "      <th>category_Jazz</th>\n",
       "      <th>category_Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>09 29, 2005</td>\n",
       "      <td>stop review sig ros album soon get otherw woul...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1127952000</td>\n",
       "      <td>15.45</td>\n",
       "      <td>p75868193</td>\n",
       "      <td>65801856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>03 23, 2006</td>\n",
       "      <td>nin hag good voc on second sing beautifu next ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1143072000</td>\n",
       "      <td>6.14</td>\n",
       "      <td>p26406868</td>\n",
       "      <td>08359673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>03 17, 2005</td>\n",
       "      <td>along almost every teen know us self titl cd o...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1111017600</td>\n",
       "      <td>8.32</td>\n",
       "      <td>p72412766</td>\n",
       "      <td>92232441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>0</td>\n",
       "      <td>11 12, 2006</td>\n",
       "      <td>put hop dream fergy fun party alb look sery mu...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1163289600</td>\n",
       "      <td>5.49</td>\n",
       "      <td>p48238587</td>\n",
       "      <td>90920112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>0</td>\n",
       "      <td>10 26, 2009</td>\n",
       "      <td>sad near four month sint trag heartbreak dea m...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1256515200</td>\n",
       "      <td>12.45</td>\n",
       "      <td>p22604624</td>\n",
       "      <td>20310190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>0</td>\n",
       "      <td>10 26, 2004</td>\n",
       "      <td>strokes recommend stud on class teach enjoy ro...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1098748800</td>\n",
       "      <td>37.99</td>\n",
       "      <td>p22016491</td>\n",
       "      <td>89076321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>0</td>\n",
       "      <td>08 31, 2009</td>\n",
       "      <td>slight disappoint cd guess expect someth gre l...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1251676800</td>\n",
       "      <td>5.00</td>\n",
       "      <td>p59697436</td>\n",
       "      <td>82712499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>0</td>\n",
       "      <td>06 15, 2004</td>\n",
       "      <td>fak get at wom real rock med afraid instead ge...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1087257600</td>\n",
       "      <td>4.66</td>\n",
       "      <td>p18498038</td>\n",
       "      <td>06613421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>0</td>\n",
       "      <td>11 2, 2000</td>\n",
       "      <td>origin pick cd almost year ago got sign mojo a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>973123200</td>\n",
       "      <td>4.70</td>\n",
       "      <td>p61312506</td>\n",
       "      <td>52736405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>0</td>\n",
       "      <td>01 21, 2015</td>\n",
       "      <td>gre</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1421798400</td>\n",
       "      <td>10.19</td>\n",
       "      <td>p01434185</td>\n",
       "      <td>46118344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>0</td>\n",
       "      <td>08 15, 2003</td>\n",
       "      <td>il get right alb opin felt lik mad radio many ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1060905600</td>\n",
       "      <td>5.99</td>\n",
       "      <td>p45396316</td>\n",
       "      <td>60874663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>0</td>\n",
       "      <td>10 6, 2006</td>\n",
       "      <td>record ok see nee cov cd patt much bet sing so...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1160092800</td>\n",
       "      <td>18.97</td>\n",
       "      <td>p58340106</td>\n",
       "      <td>37183231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>0</td>\n",
       "      <td>10 29, 2015</td>\n",
       "      <td>say 1971 deep purpl freak ready concerto group...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1446076800</td>\n",
       "      <td>6.98</td>\n",
       "      <td>p25229836</td>\n",
       "      <td>33715083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>0</td>\n",
       "      <td>12 7, 2006</td>\n",
       "      <td>answ receiv mus stor mus stor regard inquiry b...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1165449600</td>\n",
       "      <td>2.07</td>\n",
       "      <td>p37245012</td>\n",
       "      <td>59785833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>0</td>\n",
       "      <td>07 22, 2000</td>\n",
       "      <td>cd wond good solid song moby fan might lik on ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>964224000</td>\n",
       "      <td>9.47</td>\n",
       "      <td>p42372572</td>\n",
       "      <td>87886881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>0</td>\n",
       "      <td>05 20, 2008</td>\n",
       "      <td>im fan ms johansson actress perform lost trans...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1211241600</td>\n",
       "      <td>12.00</td>\n",
       "      <td>p57717030</td>\n",
       "      <td>07400204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>0</td>\n",
       "      <td>09 8, 2010</td>\n",
       "      <td>lov debut cd awesom band mus kind folksy kind ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1283904000</td>\n",
       "      <td>15.98</td>\n",
       "      <td>p50619940</td>\n",
       "      <td>05753440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0</td>\n",
       "      <td>11 20, 2007</td>\n",
       "      <td>greatest mus ev mad look describ say acoust mu...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1195516800</td>\n",
       "      <td>3.42</td>\n",
       "      <td>p51695348</td>\n",
       "      <td>74487747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>0</td>\n",
       "      <td>12 2, 2004</td>\n",
       "      <td>alexisonfir wrong try capit success peer mend ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1101945600</td>\n",
       "      <td>1.76</td>\n",
       "      <td>p91821788</td>\n",
       "      <td>53681663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>0</td>\n",
       "      <td>03 10, 2005</td>\n",
       "      <td>lik heard ofam idiot interest point punk rock ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1110412800</td>\n",
       "      <td>8.95</td>\n",
       "      <td>p21661260</td>\n",
       "      <td>71885930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>0</td>\n",
       "      <td>07 8, 2013</td>\n",
       "      <td>get best group gre talk head awesom best inclu...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1373241600</td>\n",
       "      <td>14.17</td>\n",
       "      <td>p67231993</td>\n",
       "      <td>60580658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0</td>\n",
       "      <td>05 24, 2001</td>\n",
       "      <td>favorit alb elliot smi say say light everyon c...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>990662400</td>\n",
       "      <td>16.24</td>\n",
       "      <td>p71722257</td>\n",
       "      <td>92612942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>0</td>\n",
       "      <td>09 24, 2012</td>\n",
       "      <td>id lik start say im thrilled slight stoopid fa...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1348444800</td>\n",
       "      <td>11.04</td>\n",
       "      <td>p38607226</td>\n",
       "      <td>01665229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>0</td>\n",
       "      <td>03 1, 2013</td>\n",
       "      <td>av person fear chang artistband decid evolv so...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1362096000</td>\n",
       "      <td>7.99</td>\n",
       "      <td>p16091749</td>\n",
       "      <td>40894490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8089</th>\n",
       "      <td>0</td>\n",
       "      <td>05 14, 2008</td>\n",
       "      <td>without zoom act lik know teach lov cal greate...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1210723200</td>\n",
       "      <td>15.59</td>\n",
       "      <td>p70239958</td>\n",
       "      <td>53544372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>0</td>\n",
       "      <td>02 20, 2015</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1424390400</td>\n",
       "      <td>12.29</td>\n",
       "      <td>p06680392</td>\n",
       "      <td>83329677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8492</th>\n",
       "      <td>0</td>\n",
       "      <td>06 12, 2003</td>\n",
       "      <td>clay aik run 2nd season am idol amaz voic iv n...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1055376000</td>\n",
       "      <td>10.48</td>\n",
       "      <td>p56166724</td>\n",
       "      <td>61582428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>0</td>\n",
       "      <td>07 31, 2004</td>\n",
       "      <td>lov amel larrieux alway song lik ris soph lady...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1091232000</td>\n",
       "      <td>10.28</td>\n",
       "      <td>p29013040</td>\n",
       "      <td>88154109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>0</td>\n",
       "      <td>07 25, 2008</td>\n",
       "      <td>tiesto hit sery continu disc delicy cre last m...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1216944000</td>\n",
       "      <td>16.75</td>\n",
       "      <td>p70323778</td>\n",
       "      <td>84407970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>0</td>\n",
       "      <td>03 27, 2009</td>\n",
       "      <td>dissapoint famili expect fray stray far sound ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1238112000</td>\n",
       "      <td>7.48</td>\n",
       "      <td>p69554815</td>\n",
       "      <td>80046019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>0</td>\n",
       "      <td>04 2, 2007</td>\n",
       "      <td>okay mayb see yuppy artsy weirdo peopl whor di...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1175472000</td>\n",
       "      <td>13.48</td>\n",
       "      <td>p81170876</td>\n",
       "      <td>04393946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>0</td>\n",
       "      <td>10 5, 2016</td>\n",
       "      <td>on lik phil collin class alb 2 disc set wond a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1475625600</td>\n",
       "      <td>9.48</td>\n",
       "      <td>p26080627</td>\n",
       "      <td>84821189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>0</td>\n",
       "      <td>09 6, 2014</td>\n",
       "      <td>good list tim</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1409961600</td>\n",
       "      <td>6.58</td>\n",
       "      <td>p84510925</td>\n",
       "      <td>27717930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>0</td>\n",
       "      <td>05 19, 2004</td>\n",
       "      <td>errrrplay songagain wel wak fal cur cd aveng s...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1084924800</td>\n",
       "      <td>1.13</td>\n",
       "      <td>p34122703</td>\n",
       "      <td>85310557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows Ã— 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall   reviewTime                                         reviewText  \\\n",
       "386         0  09 29, 2005  stop review sig ros album soon get otherw woul...   \n",
       "474         0  03 23, 2006  nin hag good voc on second sing beautifu next ...   \n",
       "813         0  03 17, 2005  along almost every teen know us self titl cd o...   \n",
       "1493        0  11 12, 2006  put hop dream fergy fun party alb look sery mu...   \n",
       "1773        0  10 26, 2009  sad near four month sint trag heartbreak dea m...   \n",
       "3366        0  10 26, 2004  strokes recommend stud on class teach enjoy ro...   \n",
       "3925        0  08 31, 2009  slight disappoint cd guess expect someth gre l...   \n",
       "4330        0  06 15, 2004  fak get at wom real rock med afraid instead ge...   \n",
       "4386        0   11 2, 2000  origin pick cd almost year ago got sign mojo a...   \n",
       "4594        0  01 21, 2015                                                gre   \n",
       "4668        0  08 15, 2003  il get right alb opin felt lik mad radio many ...   \n",
       "4673        0   10 6, 2006  record ok see nee cov cd patt much bet sing so...   \n",
       "5031        0  10 29, 2015  say 1971 deep purpl freak ready concerto group...   \n",
       "5621        0   12 7, 2006  answ receiv mus stor mus stor regard inquiry b...   \n",
       "5625        0  07 22, 2000  cd wond good solid song moby fan might lik on ...   \n",
       "5634        0  05 20, 2008  im fan ms johansson actress perform lost trans...   \n",
       "6195        0   09 8, 2010  lov debut cd awesom band mus kind folksy kind ...   \n",
       "6431        0  11 20, 2007  greatest mus ev mad look describ say acoust mu...   \n",
       "6610        0   12 2, 2004  alexisonfir wrong try capit success peer mend ...   \n",
       "6658        0  03 10, 2005  lik heard ofam idiot interest point punk rock ...   \n",
       "6705        0   07 8, 2013  get best group gre talk head awesom best inclu...   \n",
       "6816        0  05 24, 2001  favorit alb elliot smi say say light everyon c...   \n",
       "7234        0  09 24, 2012  id lik start say im thrilled slight stoopid fa...   \n",
       "8064        0   03 1, 2013  av person fear chang artistband decid evolv so...   \n",
       "8089        0  05 14, 2008  without zoom act lik know teach lov cal greate...   \n",
       "8340        0  02 20, 2015                                            unknown   \n",
       "8492        0  06 12, 2003  clay aik run 2nd season am idol amaz voic iv n...   \n",
       "8860        0  07 31, 2004  lov amel larrieux alway song lik ris soph lady...   \n",
       "8912        0  07 25, 2008  tiesto hit sery continu disc delicy cre last m...   \n",
       "9080        0  03 27, 2009  dissapoint famili expect fray stray far sound ...   \n",
       "9132        0   04 2, 2007  okay mayb see yuppy artsy weirdo peopl whor di...   \n",
       "9544        0   10 5, 2016  on lik phil collin class alb 2 disc set wond a...   \n",
       "9738        0   09 6, 2014                                      good list tim   \n",
       "9963        0  05 19, 2004  errrrplay songagain wel wak fal cur cd aveng s...   \n",
       "\n",
       "      summary  unixReviewTime  price     itemID reviewHash image  year  ...  \\\n",
       "386   unknown      1127952000  15.45  p75868193   65801856   NaN  2005  ...   \n",
       "474   unknown      1143072000   6.14  p26406868   08359673   NaN  2006  ...   \n",
       "813   unknown      1111017600   8.32  p72412766   92232441   NaN  2005  ...   \n",
       "1493  unknown      1163289600   5.49  p48238587   90920112   NaN  2006  ...   \n",
       "1773  unknown      1256515200  12.45  p22604624   20310190   NaN  2009  ...   \n",
       "3366  unknown      1098748800  37.99  p22016491   89076321   NaN  2004  ...   \n",
       "3925  unknown      1251676800   5.00  p59697436   82712499   NaN  2009  ...   \n",
       "4330  unknown      1087257600   4.66  p18498038   06613421   NaN  2004  ...   \n",
       "4386  unknown       973123200   4.70  p61312506   52736405   NaN  2000  ...   \n",
       "4594  unknown      1421798400  10.19  p01434185   46118344   NaN  2015  ...   \n",
       "4668  unknown      1060905600   5.99  p45396316   60874663   NaN  2003  ...   \n",
       "4673  unknown      1160092800  18.97  p58340106   37183231   NaN  2006  ...   \n",
       "5031  unknown      1446076800   6.98  p25229836   33715083   NaN  2015  ...   \n",
       "5621  unknown      1165449600   2.07  p37245012   59785833   NaN  2006  ...   \n",
       "5625  unknown       964224000   9.47  p42372572   87886881   NaN  2000  ...   \n",
       "5634  unknown      1211241600  12.00  p57717030   07400204   NaN  2008  ...   \n",
       "6195  unknown      1283904000  15.98  p50619940   05753440   NaN  2010  ...   \n",
       "6431  unknown      1195516800   3.42  p51695348   74487747   NaN  2007  ...   \n",
       "6610  unknown      1101945600   1.76  p91821788   53681663   NaN  2004  ...   \n",
       "6658  unknown      1110412800   8.95  p21661260   71885930   NaN  2005  ...   \n",
       "6705  unknown      1373241600  14.17  p67231993   60580658   NaN  2013  ...   \n",
       "6816  unknown       990662400  16.24  p71722257   92612942   NaN  2001  ...   \n",
       "7234  unknown      1348444800  11.04  p38607226   01665229   NaN  2012  ...   \n",
       "8064  unknown      1362096000   7.99  p16091749   40894490   NaN  2013  ...   \n",
       "8089  unknown      1210723200  15.59  p70239958   53544372   NaN  2008  ...   \n",
       "8340  unknown      1424390400  12.29  p06680392   83329677   NaN  2015  ...   \n",
       "8492  unknown      1055376000  10.48  p56166724   61582428   NaN  2003  ...   \n",
       "8860  unknown      1091232000  10.28  p29013040   88154109   NaN  2004  ...   \n",
       "8912  unknown      1216944000  16.75  p70323778   84407970   NaN  2008  ...   \n",
       "9080  unknown      1238112000   7.48  p69554815   80046019   NaN  2009  ...   \n",
       "9132  unknown      1175472000  13.48  p81170876   04393946   NaN  2007  ...   \n",
       "9544  unknown      1475625600   9.48  p26080627   84821189   NaN  2016  ...   \n",
       "9738  unknown      1409961600   6.58  p84510925   27717930   NaN  2014  ...   \n",
       "9963  unknown      1084924800   1.13  p34122703   85310557   NaN  2004  ...   \n",
       "\n",
       "      weekday_Saturday  weekday_Sunday  weekday_Thursday  weekday_Tuesday  \\\n",
       "386                  0               0                 1                0   \n",
       "474                  0               0                 1                0   \n",
       "813                  0               0                 1                0   \n",
       "1493                 0               1                 0                0   \n",
       "1773                 0               0                 0                0   \n",
       "3366                 0               0                 0                1   \n",
       "3925                 0               0                 0                0   \n",
       "4330                 0               0                 0                1   \n",
       "4386                 0               0                 1                0   \n",
       "4594                 0               0                 0                0   \n",
       "4668                 0               0                 0                0   \n",
       "4673                 0               0                 0                0   \n",
       "5031                 0               0                 1                0   \n",
       "5621                 0               0                 1                0   \n",
       "5625                 1               0                 0                0   \n",
       "5634                 0               0                 0                1   \n",
       "6195                 0               0                 0                0   \n",
       "6431                 0               0                 0                1   \n",
       "6610                 0               0                 1                0   \n",
       "6658                 0               0                 1                0   \n",
       "6705                 0               0                 0                0   \n",
       "6816                 0               0                 1                0   \n",
       "7234                 0               0                 0                0   \n",
       "8064                 0               0                 0                0   \n",
       "8089                 0               0                 0                0   \n",
       "8340                 0               0                 0                0   \n",
       "8492                 0               0                 1                0   \n",
       "8860                 1               0                 0                0   \n",
       "8912                 0               0                 0                0   \n",
       "9080                 0               0                 0                0   \n",
       "9132                 0               0                 0                0   \n",
       "9544                 0               0                 0                0   \n",
       "9738                 1               0                 0                0   \n",
       "9963                 0               0                 0                0   \n",
       "\n",
       "      weekday_Wednesday  category_Alternative Rock  category_Classical  \\\n",
       "386                   0                          1                   0   \n",
       "474                   0                          1                   0   \n",
       "813                   0                          1                   0   \n",
       "1493                  0                          0                   0   \n",
       "1773                  0                          0                   0   \n",
       "3366                  0                          1                   0   \n",
       "3925                  0                          0                   0   \n",
       "4330                  0                          0                   0   \n",
       "4386                  0                          1                   0   \n",
       "4594                  1                          0                   0   \n",
       "4668                  0                          1                   0   \n",
       "4673                  0                          0                   0   \n",
       "5031                  0                          0                   0   \n",
       "5621                  0                          1                   0   \n",
       "5625                  0                          1                   0   \n",
       "5634                  0                          1                   0   \n",
       "6195                  1                          1                   0   \n",
       "6431                  0                          0                   0   \n",
       "6610                  0                          1                   0   \n",
       "6658                  0                          1                   0   \n",
       "6705                  0                          1                   0   \n",
       "6816                  0                          1                   0   \n",
       "7234                  0                          1                   0   \n",
       "8064                  0                          1                   0   \n",
       "8089                  1                          0                   0   \n",
       "8340                  0                          0                   0   \n",
       "8492                  0                          0                   0   \n",
       "8860                  0                          0                   0   \n",
       "8912                  0                          0                   0   \n",
       "9080                  0                          0                   0   \n",
       "9132                  0                          1                   0   \n",
       "9544                  1                          0                   0   \n",
       "9738                  0                          0                   0   \n",
       "9963                  1                          1                   0   \n",
       "\n",
       "      category_Dance & Electronic  category_Jazz  category_Pop  \n",
       "386                             0              0             0  \n",
       "474                             0              0             0  \n",
       "813                             0              0             0  \n",
       "1493                            0              0             1  \n",
       "1773                            0              0             1  \n",
       "3366                            0              0             0  \n",
       "3925                            0              0             1  \n",
       "4330                            0              0             1  \n",
       "4386                            0              0             0  \n",
       "4594                            0              0             1  \n",
       "4668                            0              0             0  \n",
       "4673                            0              0             1  \n",
       "5031                            0              0             1  \n",
       "5621                            0              0             0  \n",
       "5625                            0              0             0  \n",
       "5634                            0              0             0  \n",
       "6195                            0              0             0  \n",
       "6431                            0              1             0  \n",
       "6610                            0              0             0  \n",
       "6658                            0              0             0  \n",
       "6705                            0              0             0  \n",
       "6816                            0              0             0  \n",
       "7234                            0              0             0  \n",
       "8064                            0              0             0  \n",
       "8089                            1              0             0  \n",
       "8340                            0              0             1  \n",
       "8492                            0              0             1  \n",
       "8860                            0              0             1  \n",
       "8912                            1              0             0  \n",
       "9080                            0              0             1  \n",
       "9132                            0              0             0  \n",
       "9544                            0              0             1  \n",
       "9738                            0              0             1  \n",
       "9963                            0              0             0  \n",
       "\n",
       "[34 rows x 672 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.loc[testDF['summary'] == 'unknown'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Sentiment Scoring with Flair, VADER, and textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FlairSentiment:\n",
    "#     \"\"\"Predict fine-grained sentiment scores using Flair.\"\"\"\n",
    "#     def __init__(self, model_file: str=None) -> None:\n",
    "#         super().__init__()\n",
    "#         from flair.models import TextClassifier\n",
    "#         self.model = TextClassifier.load(model_file)\n",
    "\n",
    "#     def score(self, text: str) -> int:\n",
    "#         from flair.data import Sentence\n",
    "#         doc = Sentence(text)\n",
    "#         self.model.predict(doc)\n",
    "\n",
    "#         if doc.labels[0].value == 'POSITIVE':\n",
    "#             pred = doc.labels[0].score\n",
    "#         else:\n",
    "#             pred = -doc.labels[0].score\n",
    "#         return pred\n",
    "\n",
    "# flair_sentiment = FlairSentiment('en-sentiment')\n",
    "\n",
    "\n",
    "# trainDF['review_sentiment'] = trainDF['reviewText'].apply(lambda x: flair_sentiment.score(x)) #Wall time: 30min 18s\n",
    "# testDF['review_sentiment'] = testDF['reviewText'].apply(lambda x: flair_sentiment.score(x)) #Wall time: 1min 30s\n",
    "# trainDF['summary_sentiment'] = trainDF['summary'].apply(lambda x: flair_sentiment.score(x)) #Wall time: 19min 17s\n",
    "# testDF['summary_sentiment'] = testDF['summary'].apply(lambda x: flair_sentiment.score(x))  #Wall time: 57.5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2714"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentence = \"The food was fine!\" \n",
    "vs = analyzer.polarity_scores(sentence)\n",
    "vs['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "trainDF['review_sentiment'] = trainDF['reviewText'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "testDF['review_sentiment'] = testDF['reviewText'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "trainDF['summary_sentiment'] = trainDF['summary'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "testDF['summary_sentiment'] = testDF['summary'].apply(lambda x: analyzer.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"The food was neutral!\" \n",
    "# TextBlob(sentence).sentiment.polarity \n",
    "\n",
    "# %%time \n",
    "# trainDF['review_sentiment'] = trainDF['reviewText'].apply(lambda x:TextBlob(x).sentiment.polarity )\n",
    "# testDF['review_sentiment'] = testDF['reviewText'].apply(lambda x:TextBlob(x).sentiment.polarity)\n",
    "# trainDF['summary_sentiment'] = trainDF['summary'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "# testDF['summary_sentiment'] = testDF['summary'].apply(lambda x:TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Split Training Data into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "h9dcmNbmzokU"
   },
   "outputs": [],
   "source": [
    "RRP_x_train, RRP_x_val, RRP_y_train, RRP_y_val = train_test_split(trainDF.drop(['overall'],axis = 1), trainDF['overall'] , random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = testDF.drop(['overall'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feturization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '1010', '11', '12', '13', '14', '15', '16', '1st', '20', '25', '2nd', '30', '35', '3rd', '40', '45', '55', '60s']\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviewText_vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \n",
    "                                                preprocessor = None, \n",
    "                                                stop_words = None, \n",
    "                                                max_features = 2000,\n",
    "                                                ngram_range = (1,2))\n",
    "\n",
    "train_reviewText = reviewText_vectorizer.fit_transform(RRP_x_train['reviewText'])\n",
    "val_reviewText = reviewText_vectorizer.transform(RRP_x_val['reviewText'])\n",
    "test_reviewText = reviewText_vectorizer.transform(testDF['reviewText'])\n",
    "print(reviewText_vectorizer.get_feature_names()[0:20])\n",
    "\n",
    "#Combine all features into sparse dataframe\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "\n",
    "# input feature dataframe \n",
    "reviewText_train =  pd.DataFrame(data = train_reviewText.toarray(), columns = reviewText_vectorizer.get_feature_names())\n",
    "\n",
    "reviewText_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#VALIDATION -------------------------------------------------------\n",
    "\n",
    "# input feature dataframe \n",
    "reviewText_val =  pd.DataFrame(data = val_reviewText.toarray(), columns = reviewText_vectorizer.get_feature_names())\n",
    "\n",
    "reviewText_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "reviewText_test =  pd.DataFrame(data = test_reviewText.toarray(), columns = reviewText_vectorizer.get_feature_names())\n",
    "\n",
    "reviewText_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '10 star', '100', '12', '12 star', '1st', '20', '20 year', '2004', '2005', '2013', '2014', '2015', '20th', '20th century', '25', '2nd', '35', '35 star', '3rd']\n"
     ]
    }
   ],
   "source": [
    "summary_vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \n",
    "                                                preprocessor = None, \n",
    "                                                stop_words = None, \n",
    "                                                max_features = 2000,\n",
    "                                                ngram_range = (1,2))\n",
    "\n",
    "train_summary = summary_vectorizer.fit_transform(RRP_x_train['summary'])\n",
    "val_summary = summary_vectorizer.transform(RRP_x_val['summary'])\n",
    "test_summary = summary_vectorizer.transform(testDF['summary'])\n",
    "\n",
    "print(summary_vectorizer.get_feature_names()[0:20])\n",
    "\n",
    "#Combine all features into sparse dataframe\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "\n",
    "# input feature dataframe \n",
    "summary_train =  pd.DataFrame(data = train_summary.toarray(), columns = summary_vectorizer.get_feature_names())\n",
    "\n",
    "summary_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#VALIDATION -------------------------------------------------------\n",
    "\n",
    "# input feature dataframe \n",
    "summary_val =  pd.DataFrame(data = val_summary.toarray(), columns = summary_vectorizer.get_feature_names())\n",
    "\n",
    "summary_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "\n",
    "summary_test =  pd.DataFrame(data = test_summary.toarray(), columns = summary_vectorizer.get_feature_names())\n",
    "\n",
    "summary_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #TRAIN -------------------------------------------------------\n",
    "# RRP_x_train = hstack((csr_matrix(feature_train), \n",
    "#                      csr_matrix(trainDF[['price','review_sentiment','summary_sentiment']]),\n",
    "#                      csr_matrix(summary_train), \n",
    "#                      csr_matrix(reviewText_train)))\n",
    "# RRP_y_train =  trainDF['overall']\n",
    "\n",
    "# #TEST -------------------------------------------------------\n",
    "# RRP_x_test = hstack((csr_matrix(feature_test), \n",
    "#                      csr_matrix(testDF[['price','review_sentiment','summary_sentiment']]),\n",
    "#                      csr_matrix(summary_test), \n",
    "#                      csr_matrix(reviewText_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RRP_x_train['sentiment'] = (RRP_x_train['review_sentiment']+RRP_x_train['summary_sentiment'])/2\n",
    "RRP_x_val['sentiment'] = (RRP_x_val['review_sentiment']+RRP_x_val['summary_sentiment'])/2\n",
    "testDF['sentiment'] = (testDF['review_sentiment']+testDF['summary_sentiment'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoricalDF_train = RRP_x_train[['weekday','category']]\n",
    "# feature_train = pd.get_dummies(data=categoricalDF_train, columns=['weekday','category'])\n",
    "\n",
    "# categoricalDF_val = RRP_x_val[['weekday','category']]\n",
    "# feature_val = pd.get_dummies(data=categoricalDF_val, columns=['weekday','category'])\n",
    "\n",
    "# categoricalDF_test = testDF[['weekday','category']]\n",
    "# feature_test = pd.get_dummies(data=categoricalDF_test, columns=['weekday','category'])\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "feature_train = RRP_x_train.drop(['reviewTime','reviewText','summary','unixReviewTime','itemID','reviewHash','image'], axis=1)\n",
    "#VALIDATION -------------------------------------------------------\n",
    "feature_val = RRP_x_val.drop(['reviewTime','reviewText','summary','unixReviewTime','itemID','reviewHash','image'], axis=1)\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "feature_test = testDF.drop(['reviewTime','reviewText','summary','unixReviewTime','itemID','reviewHash','image'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RRP_x_train = RRP_x_train.reset_index(drop=True)\n",
    "summary_train = summary_train.reset_index(drop=True)\n",
    "feature_train = feature_train.reset_index(drop=True)\n",
    "reviewText_train = reviewText_train.reset_index(drop=True)\n",
    "\n",
    "feature_val = feature_val.reset_index(drop=True)\n",
    "RRP_x_val = RRP_x_val.reset_index(drop=True)\n",
    "summary_val = summary_val.reset_index(drop=True)\n",
    "reviewText_val = reviewText_val.reset_index(drop=True)\n",
    "\n",
    "feature_test = feature_test.reset_index(drop=True)\n",
    "testDF = testDF.reset_index(drop=True)\n",
    "summary_test = summary_test.reset_index(drop=True)\n",
    "reviewText_test = reviewText_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #TRAIN -------------------------------------------------------\n",
    "# X_train = pd.concat([feature_train, RRP_x_train[['price','year','sentiment','review_sentiment','summary_sentiment']],summary_train,reviewText_train],axis = 1)\n",
    "# y_train =  RRP_y_train\n",
    "\n",
    "# #VALIDATION -------------------------------------------------------\n",
    "# X_val = pd.concat([feature_val, RRP_x_val[['price','year','sentiment','review_sentiment','summary_sentiment']],summary_val,reviewText_val],axis = 1)\n",
    "# y_val =  RRP_y_val\n",
    "\n",
    "# #TEST -------------------------------------------------------\n",
    "# X_test = pd.concat([feature_test, testDF[['price','year'ï¼Œ'sentiment','review_sentiment','summary_sentiment']],summary_test,reviewText_test],axis = 1)\n",
    "\n",
    "\n",
    "#TRAIN -------------------------------------------------------\n",
    "X_train = pd.concat([feature_train,summary_train,reviewText_train],axis = 1)\n",
    "y_train =  RRP_y_train\n",
    "\n",
    "#VALIDATION -------------------------------------------------------\n",
    "X_val = pd.concat([feature_val,summary_val,reviewText_val],axis = 1)\n",
    "y_val =  RRP_y_val\n",
    "\n",
    "#TEST -------------------------------------------------------\n",
    "X_test = pd.concat([feature_test,summary_test,reviewText_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# del RRP_x_train\n",
    "# del summary_train\n",
    "# del feature_train \n",
    "# del reviewText_train\n",
    "\n",
    "# del feature_val\n",
    "# del RRP_x_val \n",
    "# del summary_val\n",
    "# del reviewText_val \n",
    "\n",
    "# del trainDF\n",
    "# del testDF \n",
    "# del feature_test\n",
    "# del summary_test\n",
    "# del reviewText_test\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# gc.collect()\n",
    "# gc.collect()\n",
    "# gc.collect()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #TRAIN -------------------------------------------------------\n",
    "# X_train = hstack((csr_matrix(feature_train), \n",
    "#                      csr_matrix(trainDF[['price','sentiment']]),\n",
    "#                      csr_matrix(summary_train), \n",
    "#                      csr_matrix(reviewText_train)))\n",
    "# y_train =  RRP_y_train\n",
    "\n",
    "# #VALIDATION -------------------------------------------------------\n",
    "# X_val = hstack((csr_matrix(feature_train), \n",
    "#                      csr_matrix(trainDF[['price','sentiment']]),\n",
    "#                      csr_matrix(summary_train), \n",
    "#                      csr_matrix(reviewText_train)))\n",
    "# y_val =  RRP_y_val\n",
    "\n",
    "# #TEST -------------------------------------------------------\n",
    "# RRP_x_test = hstack((csr_matrix(feature_test), \n",
    "#                      csr_matrix(testDF[['price','sentiment']]),\n",
    "#                      csr_matrix(summary_test), \n",
    "#                      csr_matrix(reviewText_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #TRAIN -------------------------------------------------------\n",
    "# RRP_x_train = hstack((csr_matrix(feature_train), \n",
    "#                      csr_matrix(trainDF[['price','sentiment']]),\n",
    "#                      csr_matrix(summary_train), \n",
    "#                      csr_matrix(reviewText_train)))\n",
    "# RRP_y_train =  trainDF['overall']\n",
    "\n",
    "# #TEST -------------------------------------------------------\n",
    "# RRP_x_test = hstack((csr_matrix(feature_test), \n",
    "#                      csr_matrix(testDF[['price','sentiment']]),\n",
    "#                      csr_matrix(summary_test), \n",
    "#                      csr_matrix(reviewText_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned data for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testDF.to_csv('testDF.csv')\n",
    "# trainDF.to_csv('trainDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# feature_train.to_csv('feature_train.csv')\n",
    "# summary_train.to_csv('summary_train.csv')\n",
    "# reviewText_train.to_csv('reviewText_train.csv')\n",
    "\n",
    "# feature_test.to_csv('feature_test.csv')\n",
    "# testDF.to_csv('testDF.csv')\n",
    "# summary_test.to_csv('summary_test.csv')\n",
    "# reviewText_test.to_csv('reviewText_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# testDF = pd.read_csv('testDF.csv')\n",
    "# trainDF = pd.read_csv('trainDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 39s\n",
      "Parser   : 573 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# normalize inputs\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train \n",
    "# del X_val\n",
    "# del X_test\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.7792 - mse: 0.7007\n",
      "Epoch 2/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.6369 - mse: 0.5374\n",
      "Epoch 3/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.6166 - mse: 0.5126\n",
      "Epoch 4/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5986 - mse: 0.4937\n",
      "Epoch 5/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5851 - mse: 0.4789\n",
      "Epoch 6/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5720 - mse: 0.4647\n",
      "Epoch 7/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5628 - mse: 0.4547\n",
      "Epoch 8/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5553 - mse: 0.4459\n",
      "Epoch 9/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5461 - mse: 0.4370\n",
      "Epoch 10/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5410 - mse: 0.4308\n",
      "Epoch 11/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5369 - mse: 0.4267\n",
      "Epoch 12/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5343 - mse: 0.4234\n",
      "Epoch 13/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5292 - mse: 0.4178\n",
      "Epoch 14/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5275 - mse: 0.4152\n",
      "Epoch 15/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5257 - mse: 0.4136\n",
      "Epoch 16/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5244 - mse: 0.4115\n",
      "Epoch 17/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5217 - mse: 0.4089\n",
      "Epoch 18/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5199 - mse: 0.4067\n",
      "Epoch 19/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5191 - mse: 0.4062\n",
      "Epoch 20/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5181 - mse: 0.4054\n",
      "Epoch 21/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5141 - mse: 0.4013\n",
      "Epoch 22/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5158 - mse: 0.4035\n",
      "Epoch 23/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5109 - mse: 0.3989\n",
      "Epoch 24/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5133 - mse: 0.4009\n",
      "Epoch 25/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5113 - mse: 0.3987\n",
      "Epoch 26/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5092 - mse: 0.3971\n",
      "Epoch 27/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5082 - mse: 0.3960\n",
      "Epoch 28/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5082 - mse: 0.3964\n",
      "Epoch 29/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5073 - mse: 0.3954\n",
      "Epoch 30/30\n",
      "4375/4375 [==============================] - 6s 1ms/step - loss: 0.5063 - mse: 0.3946\n",
      "MSE on validation set is 0.4747610608281431\n"
     ]
    }
   ],
   "source": [
    "# # define model\n",
    "# # MSE on validation set is 0.5067778693405807\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(0.0002)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(64, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(0.0002)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(5, activation='softmax'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "best_error = -1\n",
    "best_params = {}\n",
    "for lam in [0.0001,0.0002,0.0003]:\n",
    "    for ep in [10,20,30]:\n",
    "#         model = Sequential()\n",
    "#         model.add(Reshape((1,X_train_scaled.shape[1])))\n",
    "#         model.add(LSTM(80, activation='sigmoid', input_shape=(1, X_train_scaled.shape[1])))\n",
    "#         model.add(Dense(60, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(lam)))\n",
    "#         model.add(Dropout(0.2))\n",
    "#         model.add(Dense(40, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(lam)))\n",
    "#         model.add(Dropout(0.2))\n",
    "#         model.add(Dense(20, activation='softmax'))\n",
    "#         model.add(Dropout(0.1))\n",
    "#         model.add(Dense(1))\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(lam)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation=\"sigmoid\",kernel_regularizer=regularizers.l2(lam)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation='sigmoid'))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # compile network\n",
    "        model.compile(loss='mse', optimizer='adam', metrics = ['mse'])\n",
    "        # fit network\n",
    "        model.fit(X_train_scaled,y_train, epochs = ep)\n",
    "        # evaluate\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        print(\"MSE on validation set is\",mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        if best_error == -1:\n",
    "            best_model = model\n",
    "            best_param = {'l2':lam,'ep':ep}\n",
    "            best_error = mean_squared_error(y_val, y_pred)\n",
    "        if mean_squared_error(y_val, y_pred) < best_error:\n",
    "            best_model = model\n",
    "            best_param = {'l2':lam,'ep':ep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation set is 0.4747610608281431\n"
     ]
    }
   ],
   "source": [
    "# verify mse with best model on validation set\n",
    "y_pred = best_model.predict(X_val_scaled)\n",
    "print(\"MSE on validation set is\",mean_squared_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119737    4.0\n",
       "72272     5.0\n",
       "158154    5.0\n",
       "65426     5.0\n",
       "30074     5.0\n",
       "         ... \n",
       "97771     5.0\n",
       "59813     5.0\n",
       "103735    5.0\n",
       "180226    5.0\n",
       "119389    5.0\n",
       "Name: overall, Length: 60000, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0785718],\n",
       "       [4.928782 ],\n",
       "       [4.867382 ],\n",
       "       ...,\n",
       "       [4.8526893],\n",
       "       [4.0465136],\n",
       "       [4.8157644]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRP = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction_list = []\n",
    "for r in RRP:\n",
    "    prediction_list.append(r[0])\n",
    "\n",
    "    \n",
    "predictions = open('rating_prediction.csv', 'w')\n",
    "rate = 0\n",
    "for l in open('rating_pairs.csv'):\n",
    "    if l.startswith('userID'):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,p = l.strip().split('-')\n",
    "    predictions.write(u + '-' + p +  ',' + str(prediction_list[rate]) + '\\n')\n",
    "    rate += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6583834],\n",
       "       [4.786703 ],\n",
       "       [4.8100166],\n",
       "       ...,\n",
       "       [4.726027 ],\n",
       "       [2.961877 ],\n",
       "       [4.8356757]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle score 0.49979"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
